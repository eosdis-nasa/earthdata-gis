[
  {
    "objectID": "webinar-content/Earthdata Webinar TS Analysis.html",
    "href": "webinar-content/Earthdata Webinar TS Analysis.html",
    "title": "Earthdata GIS",
    "section": "",
    "text": "Accessing POWER Monthly Meteorology - Earth Skin Surface Temperature (TS) Image Service Data\nThis document performs a quick demonstration using NASA Earthdata Image Services in Python, focusing in on the Prediction of Worldwide Energy Resources (commonly known as POWER) annual meteorology dataset. While primarily relying on the ArcGIS API for Python, this document also will briefly acknowledge some of the other potential libraries folks may utilize for visualization and analytics. While not demonstrated in this document, it is worth nothing some specific services – such as the POWER service tested below – also have separate APIs that can be called upon using their own schema.\n\n\n\nimage.png\n\n\nFor this demo, we will be taking a look at surface temperature at 7 locations around the world and plot their data across over 40 years. We will do this by pinging the NASA POWER annual meteorology datasets’ Earth Skin Temperature parameter (TS).\nGetting started, we are going to take a look at the parameter information to familiarize ourselves with the structure of the dataset. We collect multidimensional information from the REST endpoint’s capabilities using the Python library requests, which returns a json that has most of the numerical data in a non-geospatial format, including descriptive variable metadata, dimensions, and values. We start using requests for the sake of sampling some different ways to access this data, but this information could also be acquired using the ArcGIS API for Python access the slices class of the ImageryLayer object which we will be doing again below.\n\nimport requests\n\nservice_url = 'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_ANNUAL_METEOROLOGY_UTC/ImageServer'\nurl = service_url+'/multiDimensionalInfo?returnDimensionValues=always&f=pjson'\n\nr = requests.get(url)\ndisplay(r.json()['multidimensionalInfo']['variables'][0].keys())\ndisplay(r.json()['multidimensionalInfo']['variables'][0])\n\ndict_keys(['name', 'unit', 'statistics', 'histograms', 'attributes', 'dimensions'])\n\n\n{'name': 'CDD10',\n 'unit': 'degree-day',\n 'statistics': [{'min': 0,\n   'max': 8972.0625,\n   'mean': 2224.8882386419177,\n   'standardDeviation': 2508.1968623077223,\n   'median': 8972.0625,\n   'mode': 0,\n   'skipX': 1,\n   'skipY': 1,\n   'count': 21313440}],\n 'histograms': [{'size': 256,\n   'min': 0,\n   'max': 8972.0625,\n   'counts': [4454073,\n    81729,\n    75748,\n    68861,\n    65326,\n    60084,\n    57769,\n    54291,\n    50376,\n    49185,\n    46836,\n    44614,\n    42863,\n    40343,\n    39301,\n    37973,\n    36540,\n    34631,\n    33351,\n    32990,\n    32381,\n    30687,\n    28689,\n    27886,\n    27645,\n    26923,\n    26813,\n    26353,\n    24897,\n    24586,\n    24306,\n    23377,\n    22936,\n    23383,\n    22305,\n    21689,\n    21722,\n    20851,\n    1]}],\n 'attributes': {'long_name': 'Cooling Degree Days Above 10 C',\n  'standard_name': 'Cooling_Degree_Days_Above_10_C',\n  '_FillValue': -999},\n 'dimensions': [{'name': 'StdTime',\n   'field': 'StdTime',\n   'unit': 'ISO8601',\n   'interval': 365.2425,\n   'hasRegularIntervals': True,\n   'intervalUnit': 'Days',\n   'extent': [378604800000, 1640882880000],\n   'hasRanges': False,\n   'values': [378604800000,\n    410161752000,\n    441718704000,\n    473275656000,\n    504832608000,\n    536389560000,\n    567946512000,\n    599503464000,\n    631060416000,\n    662617368000,\n    694174320000,\n    725731272000,\n    757288224000,\n    788845176000,\n    820402128000,\n    851959080000,\n    883516032000,\n    915072984000,\n    946629936000,\n    978186888000,\n    1009743840000,\n    1041300792000,\n    1072857744000,\n    1104414696000,\n    1135971648000,\n    1167528600000,\n    1199085552000,\n    1230642504000,\n    1262199456000,\n    1293756408000,\n    1325313360000,\n    1356870312000,\n    1388427264000,\n    1419984216000,\n    1451541168000,\n    1483098120000,\n    1514655072000,\n    1546212024000,\n    1577768976000,\n    1609325928000,\n    1640882880000]}]}\n\n\nNow let’s parse through this information to make a bit more human readable. Here we dug up all parameters with their long names and measurement units. The POWER project has both annual and monthly versions for a whole spread of climate, radiation, and meteorological parameters. As previously mentioned, we will be looking at earth skin surface temperature (TS).\n\noutDict = {}\n \nfor variable_dict in r.json()['multidimensionalInfo']['variables']:\n    outDict[variable_dict['name']] = [variable_dict['attributes']['standard_name'],variable_dict['unit']]\n \ndisplay(pd.DataFrame.from_dict(outDict,orient='index',columns=['Long Name','Unit of Measurement']))\n\n\n\n\n\n\n\n\nLong Name\nUnit of Measurement\n\n\n\n\nCDD10\nCooling_Degree_Days_Above_10_C\ndegree-day\n\n\nCDD18_3\nCooling_Degree_Days_Above_18.3_C\ndegree-day\n\n\nDISPH\nZero_Plane_Displacement_Height\nm\n\n\nEVLAND\nEvaporation_Land\nkg m-2 s-1\n\n\nEVPTRNS\nEvapotranspiration_Energy_Flux\nW m-2\n\n\nFROST_DAYS\nFrost_Days\ndays\n\n\nGWETTOP\nSurface_Soil_Wetness\n1\n\n\nHDD10\nHeating_Degree_Days_Below_10_C\ndegree-day\n\n\nHDD18_3\nHeating_Degree_Days_Below_18.3_C\ndegree-day\n\n\nPBLTOP\nPlanetary_Boundary_Layer_Top_Pressure\nPa\n\n\nPRECSNOLAND_SUM\nSnow_Precipitation_Land_Sum\nkg m-2 s-1\n\n\nPRECTOTCORR_SUM\nPrecipitation_Corrected_Sum\nkg m-2 s-1\n\n\nPS\nSurface_Pressure\nPa\n\n\nQV10M\nSpecific_Humidity_at_10_Meters\nkg/kg\n\n\nQV2M\nSpecific_Humidity_at_2_Meters\nkg/kg\n\n\nRH2M\nRelative_Humidity_at_2_Meters\n%\n\n\nT10M\nTemperature_at_10_Meters\nK\n\n\nT2M\nTemperature_at_2_Meters\nK\n\n\nT2MDEW\nDew/Frost_Point_at_2_Meters\nK\n\n\nT2MWET\nWet_Bulb_Temperature_at_2_Meters\nK\n\n\nTO3\nTotal_Column_Ozone\nDobsons\n\n\nTQV\nTotal_Column_Precipitable_Water\nkg m-2\n\n\nTS\nEarth_Skin_Temperature\nK\n\n\nWD10M\nWind_Direction_at_10_Meters\nDegrees\n\n\nWD2M\nWind_Direction_at_2_Meters\nDegrees\n\n\nWD50M\nWind_Direction_at_50_Meters\nDegrees\n\n\nWS10M\nWind_Speed_at_10_Meters\nm/s\n\n\nWS2M\nWind_Speed_at_2_Meters\nm/s\n\n\nWS50M\nWind_Speed_at_50_Meters\nm/s\n\n\n\n\n\n\n\nWe are simply getting a bit more information on the specific variable we are exploring. These arguments can be used for exploratory queries on other NASA Earthdata datasets.\n\nattribute = 'variableName'\nparameter = 'TS'\n\nsliceinfo_url = f'{service_url}/slices?multidimensionalDefinition=%7B%22{attribute}%22%3A%22{parameter}%22%7D&f=json'\n\nr = requests.get(sliceinfo_url)\n\nfrom time import strftime,localtime\n\ntime_stamp = strftime('%Y',localtime(int(str(r.json()['slices'][0]['multidimensionalDefinition'][0]['values'][0])[0:9])))\nslice_count = len(r.json()['slices'])\n\ndisplay(f'Number of time stamps: {slice_count}, starting at {time_stamp}')\n\n'Number of time stamps: 41, starting at 1981'\n\n\nHere we load in some of our coordinates to test and show a sample layout of a given slice that we will be querying our ArcGIS API for Python via the Imagery Layer. Output slice information shown below.\n\nfrom arcgis.raster import ImageryLayer\nfrom datetime import datetime\n\nlayer = ImageryLayer(r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_ANNUAL_METEOROLOGY_UTC/ImageServer')\n#List of slice information\nslice_list = layer.slices()['slices']\n\ndisplay(slice_list[0])\n\n#Data to test\nlocs = {\n    'White House':(-77,39),\n    'Lima':(-77,-12),\n    'Phoenix':(-112,33.6),\n    'Dehli':(77.2,28.6),\n    'Origin':(0,0),\n    'France':(0,45),\n    'Uluru':(131,-25.3)\n    }\n    \nvarData = {}\n\n{'sliceId': 0,\n 'multidimensionalDefinition': [{'variableName': 'CDD10',\n   'dimensionName': 'StdTime',\n   'values': [378604800000]}]}\n\n\nFinally, we can get to querying the data we need. We drill down to find the appropriate slice information and slices, then convert epoch time to get something more human readable. The primary query we will be doing is using the identify function for the imagery layer, which is similar to the getcapabilities function. We call the lats and lons from our dictionary we built previously, convert from K to C, and make a quick dataframe with our result data.\n\nfor slice_set in slice_list:\n    sliceId = slice_set['sliceId']\n    multi_def = slice_set['multidimensionalDefinition'][0]\n    #[variableName,dimensionName,values]\n    var_name = multi_def['variableName']\n    if var_name == parameter:\n        time_epoch = multi_def['values'][0]\n\n        #Convert epoch time (e.g., 349747200000 to GMT)\n        yr = datetime.fromtimestamp(time_epoch/1000).year\n        \n        #Declare initial dict pair\n        varData[sliceId] = [time_epoch,yr]\n\n        #Perform Identifies on all coordinates\n        for loc in locs:\n            lon = locs[loc][0]\n            lat = locs[loc][1]\n\n            #Core data query\n            result = layer.identify(geometry={\"x\":lon,\"y\":locs[loc][1]},slice_id=sliceId)['value']\n            varData[sliceId].append(float(result)-273.15)\n\nimport pandas as pd\n\ndf = pd.DataFrame.from_dict(varData,orient='index',columns=['Epoch Time','Year']+list(locs.keys()))\ndisplay(df.head())\n\n\n\n\n\n\n\n\nEpoch Time\nYear\nWhite House\nLima\nPhoenix\nDehli\nOrigin\nFrance\nUluru\n\n\n\n\n697\n378604800000\n1981\n11.881\n17.741\n22.483\n25.788\n25.967\n12.100\n21.389\n\n\n698\n410161752000\n1982\n12.061\n18.178\n20.647\n24.522\n25.248\n12.717\n20.834\n\n\n699\n441718704000\n1983\n12.350\n19.295\n20.639\n24.741\n25.452\n12.241\n21.569\n\n\n700\n473275656000\n1984\n11.803\n17.702\n21.014\n25.772\n26.022\n11.748\n20.959\n\n\n701\n504832608000\n1985\n12.498\n17.381\n21.084\n25.428\n25.741\n11.569\n21.936\n\n\n\n\n\n\n\nWe take this data and throw it into a matplotlib pyplot to see our results, which we could from here dig into more detail on areas of interest.\n\nimport matplotlib.pyplot as plt\n \nxpoints = df['Year']\nfor loc in locs:\n    ypoints = df[loc]\n    plt.plot(xpoints,ypoints,label=loc)\n\nplt.legend(loc=\"upper left\"), plt.xlabel(\"Year\"), plt.ylabel(\"Average Annual Surface Temp. (C)\")\nplt.show()\n\n\n\n\n\n\n\n\nHere we used the ArcGIS API which loads a lot of the REST endpoint information & GetCapabilities into an imagery layer which can also be done by hardcoding in requests (e.g., calling all TS slices) if you would prefer to test in the GUI before converting into Python.\nAdditional modules include arcpy and qgis for use in their respective ArcGIS Pro and QGIS platforms. Data can also be loaded and filtered using SQL queries or loading into GeoDataFrames for more pandas analysis using XArray if you are more comfortable in either of those environments. For all of these, documentation and tutorials have been published with more in development based on community feedback and specific challenges.\n\n\n\nimage.png"
  },
  {
    "objectID": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html",
    "href": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html",
    "title": "Accessing, Analyzing, & Visualizing TEMPO data through ArcGIS Image Services Programmatically (Bounding Box)",
    "section": "",
    "text": "Overview Selected TEMPO data have been processed into free, publicly available ArcGIS image services that provide pre-filtered, analysis-ready imagery/data.\nThis notebook illustrates the following:\nWhy ArcGIS image services? Each TEMPO ArcGIS image service is hosted at a service URL, which has several built-in functions provided through the ArcGIS image service REST API. These functionalities can be accessed via webpage interfaces or called programatically, providing ways to access, analyze, and display the TEMPO data."
  },
  {
    "objectID": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html#setup",
    "href": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html#setup",
    "title": "Accessing, Analyzing, & Visualizing TEMPO data through ArcGIS Image Services Programmatically (Bounding Box)",
    "section": "1. Setup",
    "text": "1. Setup\n\n1.1 Install Python packages\n\n# Install Python packages if not available\n#!pip install --quiet ipywidgets nodejs traitlets numpy pandas matplotlib\n\n\n\n1.2 Import Python libraries\n\n# For accessing data and creating chart\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport datetime as dt\nfrom datetime import datetime, timezone\nimport json\n\n# For creating interactive mapper\nfrom ipyleaflet import Map, ImageService, basemaps, WidgetControl\nfrom ipywidgets import SelectionSlider, Layout, Label, VBox\nfrom ipywidgets import Output, HTML\n\n# Set dataframe view options to ensure all rows appear (optional)\npd.set_option(\"display.max_rows\", None)\n\n\n\n1.3 Enable function to convert between human-readable dates and Unix timestamps\nThe TEMPO image services store the timestamp of each data scan as a Unix timestamp (e.g., 1752582321), which is the number of seconds since January 1, 1970 UTC. As these integers are not intuitive, we will use two custom functions to convert between Unix timestamps and human-readable date time strings.\n\n# function to take input time as string and convert to integer of seconds since unix epoch UTC (Jan 1, 1970)\ndef convert_to_milliseconds(date_time_str):\n    \"\"\"Converts a date-time string in 'YYYY-MM-DD HH:MM:SS' format to milliseconds since epoch.\"\"\"\n    inputDate = dt.datetime.strptime(date_time_str, \"%Y-%m-%d %H:%M:%S\")\n    return int(inputDate.replace(tzinfo=timezone.utc).timestamp() * 1000)\n\n\n# function to take input time as integer of seconds since unix epoch UTC (Jan 1, 1970) and convert to string in 'YYYY-MM-DDTHH:MM:SSZ' format\ndef convert_from_milliseconds(milliseconds_since_epoch):\n    \"\"\"Converts milliseconds since epoch to a date-time string in 'YYYY-MM-DDTHH:MM:SSZ' format.\"\"\"\n    inputDateMilli = datetime.fromtimestamp((milliseconds_since_epoch) / 1000, tz=timezone.utc)\n    return inputDateMilli.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
  },
  {
    "objectID": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html#user-selections",
    "href": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html#user-selections",
    "title": "Accessing, Analyzing, & Visualizing TEMPO data through ArcGIS Image Services Programmatically (Bounding Box)",
    "section": "2. User Selections",
    "text": "2. User Selections\nUsers can select the variable, time window, and bounding box (Xmin, Ymin, Xmax, Ymax) of interest or use defaults. Several of the following sections allow users to choose between various options to tailor this code to their desired analysis. These sections have a default option that will be used if no changes are made. To select one of the other available options, users must adjust which lines of code are commented out (the # at the beginning of the code line) as noted in the instructions for the section.\n\n2.1 Choose TEMPO product/variable of interest\nThe default is TEMPO NO2 tropospheric column. Users may instead select formaldehyde (HCHO) total column or total column ozone (only one service/variable can be selected at a time).\n\n# NOTE: Use exactly one image_service_url + variable_name. Comment out others.\n\n# Option 1: NO2 image service (default)\n# image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C2930763263-LARC_CLOUD/TEMPO_NO2_L3_V03_HOURLY_TROPOSPHERIC_VERTICAL_COLUMN/ImageServer\"\n# variable_name = \"NO2_Troposphere\"\n\n# Option 2: Formaldehyde image service\n# image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C2930761273-LARC_CLOUD/TEMPO_HCHO_L3_V03_HOURLY_VERTICAL_COLUMN/ImageServer\"\n# variable_name = \"HCHO\"\n\n# Option 3: Total Column Ozone\n# image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C2930764281-LARC_CLOUD/TEMPO_O3TOT_L3_V03_HOURLY_OZONE_COLUMN_AMOUNT/ImageServer\"\n# variable_name = \"Ozone_Column_Amount\"\n\n# Option 4: NO2 Image Service v4\n# image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C3685896708-LARC_CLOUD/TEMPO_NO2_L3_V04_HOURLY_TROPOSPHERIC_VERTICAL_COLUMN/ImageServer\"\n# variable_name = \"NO2_Troposphere\"\n\n# Option 5: Formaldehyde Image Service v4\nimage_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C3685897141-LARC_CLOUD/TEMPO_HCHO_L3_V04_HOURLY_VERTICAL_COLUMN/ImageServer\"\nvariable_name = \"HCHO\"\n\n# Option 6: Ozone Image Service v4\n# image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C3685896625-LARC_CLOUD/TEMPO_O3TOT_L3_V04_HOURLY_OZONE_COLUMN_AMOUNT/ImageServer\"\n# variable_name = \"Ozone_Column_Amount\"\n\n\n\n2.2 Choose time period of interest\nThere are two options: * Option 1 (default): Time period is yesterday (last 24 hours from present) * Option 2: Manually select any time period within scope of TEMPO mission (August 2, 2023 - present)\nNote: User must comment out the option that is not in use. By default, Option 2 is commented out.\n\n# Choose starting and ending dates to run against\n\nyesterday = dt.datetime.today() - dt.timedelta(days=1)\ntoday = dt.datetime.today()\n\n# Option 1 (Default): Yesterday - today NOTE: converts local computer time to UTC\n# If using Google Colab, use this time_options to account for a bug that occurs if more than 5 timeslices are called at a time\n# time_options = [(time_strings[i], timestamps[i]) for i in range(5)]\n\"\"\"Note: If using Option 2, comment out the two lines below:\"\"\"\n# start_date_time_str = str(dt.datetime(yesterday.year, yesterday.month, yesterday.day))\n# end_date_time_str = str(dt.datetime(today.year, today.month, today.day, today.hour))\n\n# OR\n\n# Option 2: If not using Google Colab, use this time_options to call all timeslices. Change specifc time period of interest as desired\n\"\"\"Note: If using Option 1, comment out the two lines below:\"\"\"\nstart_date_time_str = \"2025-09-20 0:01:00\" #in 'YYYY-MM-DD HH:MM:SS' format \"2025-04-20 12:00:00\"\nend_date_time_str = \"2025-09-25 05:00:00\" #in 'YYYY-MM-DD HH:MM:SS' format \"2025-05-25 12:00:00\"\n\n# Convert user input dates to milliseconds since epoch\nstart_time = convert_to_milliseconds(start_date_time_str)\nend_time = convert_to_milliseconds(end_date_time_str)\n\nprint(f\"The time period of interest has been defined as: Start = {start_date_time_str} ({start_time}); End: = {end_date_time_str} ({end_time})\")\n\nThe time period of interest has been defined as: Start = 2025-09-20 0:01:00 (1758326460000); End: = 2025-09-25 05:00:00 (1758776400000)\n\n\n\n\n2.3 Choose bounding box (envelope) of interest\nProvide WGS84 (EPSG:4326) coordinates. Example below is Hampton Roads, VA area. Update as needed.\n\n# Bounding box / geometry envelope in WGS84 (EPSG:4326)\nxmin, ymin = -76.6, 37.1\nxmax, ymax = -76.3, 37.3\n\ngeometry_envelope = {\n    \"xmin\": xmin,\n    \"ymin\": ymin,\n    \"xmax\": xmax,\n    \"ymax\": ymax,\n    \"spatialReference\": {\"wkid\": 4326}\n}\nprint(\"Geometry (xmin, ymin, xmax, ymax):\", xmin, ymin, xmax, ymax)\n\nGeometry (xmin, ymin, xmax, ymax): -76.6 37.1 -76.3 37.3"
  },
  {
    "objectID": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html#send-get-samples-request",
    "href": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_Bounding_Box.html#send-get-samples-request",
    "title": "Accessing, Analyzing, & Visualizing TEMPO data through ArcGIS Image Services Programmatically (Bounding Box)",
    "section": "4.1 Send Get Samples request",
    "text": "4.1 Send Get Samples request\n\n4.1 Get Samples request\nThe user provided information above (variable, time, bounding box) are used to create a Get Samples request, which is sent to the service API. The data response is then stored in a json to access.\n\n# Create URL for Get Samples request\nbase_url = f\"{image_service_url}/getSamples/\"\n\nparams = {\n    \"geometry\": json.dumps(geometry_envelope),\n    \"geometryType\": \"esriGeometryEnvelope\",\n    \"sampleDistance\": \"\",              # optional thinning\n    \"sampleCount\": \"\",                 # optional limit\n    \"mosaicRule\": json.dumps({\"multidimensionalDefinition\":[{\"variableName\": variable_name}]}),\n    \"pixelSize\": \"\",                   # e.g., \"0.05\" to coarsen, if desired\n    \"returnFirstValueOnly\": \"false\",\n    \"interpolation\": \"RSP_BilinearInterpolation\",  # for smoother columns; use NN for exact pixel values\n    \"outFields\": \"\",\n    \"sliceId\": \"\",\n    \"time\": f\"{start_time},{end_time}\",\n    \"f\": \"pjson\"\n}\n\n# Make the request to the service API\nresponse = requests.get(base_url, params=params)\nresponse.raise_for_status()\ndata = response.json()\n\n\n\n4.2 Extract data into a dataframe\nThe returned json contains the variable, timestamps, and data values for the TEMPO scans in the selected time period. Not all scans in the selected time period may have data for the selected envelope. The retrieved data are iterated through to find which scans had data for the selected envelope and adding those data values with their corresponding timestamps to a dataframe. The dataframe is displayed in a table format.\n\n# Extract relevant information into a DataFrame\nsamples = []\nfor sample in data.get(\"samples\", []):\n    attributes = sample.get(\"attributes\", {})\n    var_value = attributes.get(variable_name)\n\n    # Only include the sample if it has a valid value for the variable of interest\n    \"\"\"Note: this will result in timeslices being excluded if there are no data within the\n    bounding box. Code may be modified to see all timestamps (i.e., include TEMPO scans\n    where there are no data).\"\"\"\n    if var_value is not None:  # keep zeros as valid values\n        try:\n            samples.append(\n                {\n                    \"StdTime\": attributes[\"StdTime\"],\n                    variable_name: float(var_value),  # Convert to float\n                }\n            )\n        except (TypeError, ValueError):\n            # Skip if the value cannot be converted to float\n            continue\n\n# Convert the list to a DataFrame\ndf = pd.DataFrame(samples)\n\n# Check if dataframe is empty. If not empty, convert StdTime from Unix timestamp (milliseconds) to datetime and print dataframe\nif df.empty:\n    print(\n        f\"No {variable_name} data found between {start_date_time_str} - {end_date_time_str} \"\n        f\"for envelope ({xmin}, {ymin}, {xmax}, {ymax}).\"\n    )\nelse:\n    df[\"StdTime\"] = pd.to_datetime(df[\"StdTime\"], unit=\"ms\")\n    print(df.head())\n\n              StdTime          HCHO\n0 2025-09-20 11:41:28  1.167813e+16\n1 2025-09-20 12:21:36  1.275896e+16\n2 2025-09-20 13:01:44  1.747650e+16\n3 2025-09-20 14:01:44  1.018995e+16\n4 2025-09-20 15:01:44  1.132089e+16\n\n\n\n\n4.3 Display the data in a chart\nThe data in the dataframe can be displayed in a chart. The chart can be exported for later use (this option is commented out by default).\n\n# Group by time to calculate the average value for each timestamp\ndf_avg = df.groupby(\"StdTime\", as_index=False)[variable_name].mean()\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(df_avg[\"StdTime\"], df_avg[variable_name], marker=\"o\", linestyle=\"-\")\n\n# Set title and labels--user may change\nplt.title(f\"Average {variable_name} Over Time (Envelope)\")  # User may change title as desired\nplt.xlabel(\"Time (UTC)\")\nplt.ylabel(\n    f\"Average {variable_name} (molecules/cm^2)\"\n)  # Change unit as needed for variable selected (e.g., Ozone total is Dobson units)\n\n# Set grid, tick marks, and format\nplt.grid(True)\nax = plt.gca()\nax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M:%S\"))\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Optional: Save the plot to a local folder (include file path). Format set to PNG as default but can be changed.\n# plt.savefig(\"outputGraph.png\", format=\"png\")\n\n# Show plot in notebook\nplt.show()"
  },
  {
    "objectID": "tutorials/getting-started-arcgis.html",
    "href": "tutorials/getting-started-arcgis.html",
    "title": "Getting Started with Image Services",
    "section": "",
    "text": "NASA Image Services can also be accessed programmatically using a variety of standard, open source, or licensed Python libraries. This section will outline how this data may be accessed using requests on the REST endpoint, using the qgis module associated with the open source OSGeo QGIS desktop software, and the arcpy (Desktop) and arcgis (Online) licensed libraries associated with the ArcGIS suite.\n\n\nThe built-in library requests allows the user to programmatically access many of the underlying REST service interface capabilities such as statistics, image export, histograms, or slices. For example, users can acquire various statistics in specific fields in JSON format:\n\nimport requests\nimport pandas as pd\n \nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/multiDimensionalInfo?returnDimensionValues=always&f=pjson'\nr = requests.get(url)\n \noutDict = {}\n \nfor variable_dict in r.json()['multidimensionalInfo']['variables']:\n    outDict[variable_dict['name']] = [variable_dict['attributes']['standard_name'],variable_dict['unit']]\n \ndisplay(pd.DataFrame.from_dict(outDict,orient='index',columns=['Long Name','Unit of Measurement']))\n\n\n\n\n\n\n\n\nLong Name\nUnit of Measurement\n\n\n\n\nCDD10\nCooling_Degree_Days_Above_10_C\ndegree-day\n\n\nCDD18_3\nCooling_Degree_Days_Above_18.3_C\ndegree-day\n\n\nDISPH\nZero_Plane_Displacement_Height\nm\n\n\nEVLAND\nEvaporation_Land\nkg m-2 s-1\n\n\nEVPTRNS\nEvapotranspiration_Energy_Flux\nW m-2\n\n\nFROST_DAYS\nFrost_Days\ndays\n\n\nGWETTOP\nSurface_Soil_Wetness\n1\n\n\nHDD10\nHeating_Degree_Days_Below_10_C\ndegree-day\n\n\nHDD18_3\nHeating_Degree_Days_Below_18.3_C\ndegree-day\n\n\nPBLTOP\nPlanetary_Boundary_Layer_Top_Pressure\nPa\n\n\nPRECSNOLAND_SUM\nSnow_Precipitation_Land_Sum\nkg m-2 s-1\n\n\nPRECTOTCORR_SUM\nPrecipitation_Corrected_Sum\nkg m-2 s-1\n\n\nPS\nSurface_Pressure\nPa\n\n\nQV10M\nSpecific_Humidity_at_10_Meters\nkg/kg\n\n\nQV2M\nSpecific_Humidity_at_2_Meters\nkg/kg\n\n\nRH2M\nRelative_Humidity_at_2_Meters\n%\n\n\nT10M\nTemperature_at_10_Meters\nK\n\n\nT2M\nTemperature_at_2_Meters\nK\n\n\nT2MDEW\nDew/Frost_Point_at_2_Meters\nK\n\n\nT2MWET\nWet_Bulb_Temperature_at_2_Meters\nK\n\n\nTO3\nTotal_Column_Ozone\nDobsons\n\n\nTQV\nTotal_Column_Precipitable_Water\nkg m-2\n\n\nTS\nEarth_Skin_Temperature\nK\n\n\nWD10M\nWind_Direction_at_10_Meters\nDegrees\n\n\nWD2M\nWind_Direction_at_2_Meters\nDegrees\n\n\nWD50M\nWind_Direction_at_50_Meters\nDegrees\n\n\nWS10M\nWind_Speed_at_10_Meters\nm/s\n\n\nWS2M\nWind_Speed_at_2_Meters\nm/s\n\n\nWS50M\nWind_Speed_at_50_Meters\nm/s\n\n\n\n\n\n\n\n\nt2m_url = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/statistics?variable=T2M&renderingRule=&f=pjson'\nr_t2m = requests.get(t2m_url)\n \nstats = r_t2m.json()['statistics'][0]\ndisplay(stats)\n\n{'min': 199.078125,\n 'max': 314.9453125,\n 'mean': 278.25700790851954,\n 'standardDeviation': 21.776876164664852,\n 'median': 282.22987132352944,\n 'mode': 299.49635416666666,\n 'skipX': 1,\n 'skipY': 1,\n 'count': 130999680}\n\n\nSimilarly, querying this variable can show what slice identifiers correspond to this variable. Queries on specific points for slices can be browsed on the slices capability pane. A sample is shown below:\n\nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/slices?multidimensionalDefinition=%7B%22variableName%22%3A%22T2M%22%7D&f=json'\n \nr = requests.get(url)\ndisplay(r.json()['slices'][25:55])\n \n#'Values' dictionary list indices indicate epoch time; e.g., 415490850000 indicates Wednesday, March 2, 1983 10:07:30 PM GMT (per &lt;https://www.epochconverter.com/&gt;)\n\n[{'sliceId': 8593,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [415238400000]}]},\n {'sliceId': 8594,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [417916800000]}]},\n {'sliceId': 8595,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [420508800000]}]},\n {'sliceId': 8596,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [423187200000]}]},\n {'sliceId': 8597,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [425779200000]}]},\n {'sliceId': 8598,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [428457600000]}]},\n {'sliceId': 8599,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [431136000000]}]},\n {'sliceId': 8600,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [433728000000]}]},\n {'sliceId': 8601,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [436406400000]}]},\n {'sliceId': 8602,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [438998400000]}]},\n {'sliceId': 8603,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [441676800000]}]},\n {'sliceId': 8604,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [444355200000]}]},\n {'sliceId': 8605,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [446860800000]}]},\n {'sliceId': 8606,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [449539200000]}]},\n {'sliceId': 8607,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [452131200000]}]},\n {'sliceId': 8608,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [454809600000]}]},\n {'sliceId': 8609,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [457401600000]}]},\n {'sliceId': 8610,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [460080000000]}]},\n {'sliceId': 8611,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [462758400000]}]},\n {'sliceId': 8612,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [465350400000]}]},\n {'sliceId': 8613,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [468028800000]}]},\n {'sliceId': 8614,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [470620800000]}]},\n {'sliceId': 8615,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [473299200000]}]},\n {'sliceId': 8616,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [475977600000]}]},\n {'sliceId': 8617,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [478396800000]}]},\n {'sliceId': 8618,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [481075200000]}]},\n {'sliceId': 8619,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [483667200000]}]},\n {'sliceId': 8620,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [486345600000]}]},\n {'sliceId': 8621,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [488937600000]}]},\n {'sliceId': 8622,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [491616000000]}]}]\n\n\nFinally, by browsing this REST endpoint capability or parsing it via JSON, a user can query a specific coordinate (100,50) for August 2nd, 1983 (slice 50, epoch time 428639580000):\n\nfrom IPython.display import Markdown\n \nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/identify?geometry=%7B%22x%22%3A100%2C%22y%22%3A50%7D&geometryType=esriGeometryPoint&mosaicRule=&renderingRule=&renderingRules=&pixelSize=&sliceId=1950&time=&returnGeometry=true&returnCatalogItems=true&returnPixelValues=true&processAsMultidimensional=true&maxItemCount=10&f=pjson'\n \nr = requests.get(url)\ndisplay(Markdown(\"*Sample requests JSON response:*\"))\ndisplay(r.json())\n \nvalue = r.json()['value'].split('.')[0]\nMarkdown(f\"**Query result:** {value} K\")\nr = requests.get(r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/statistics?variable=T2M&renderingRule=&f=pjson')\ntemp_min = r.json()['statistics'][0]['min']\n\nSample requests JSON response:\n\n\n{'objectId': 0,\n 'name': 'Pixel',\n 'value': '2.28882e-05',\n 'location': {'x': 100,\n  'y': 50,\n  'spatialReference': {'wkid': 4326, 'latestWkid': 4326}},\n 'properties': {'Attributes': [{'Variable': 'EVLAND',\n    'StdTime': 1501459200000,\n    'StdTime_Max': 1501459200000}]},\n 'catalogItems': None,\n 'catalogItemVisibilities': []}\n\n\n\n\n\nUsers may perform much of the same functionality in web maps and in desktop software using Esri-developed Python packages arcpy and arcgis. This section of the tutorial will focus on the freely available online arcgis module which can be used easily in Esri’s Experience Builder, Jupyter notebooks, or across a wide variety of programming and web environments and use cases.\nThe below examples use the GPM and POWER image services.\nA user can import a give Image Service into a web map as follows utilizing the arcgis.mapping utilities to generate a custom map:\n\nimport arcgis\n \nm = arcgis.mapping.WebMap()\n \nGPM_url = r'https://arcgis.gesdisc.eosdis.nasa.gov/authoritative/rest/services/GPM_3IMERGHHE_06/ImageServer'\n \nlayer = arcgis.raster.ImageryLayer(GPM_url)\nm.add_layer(layer)\ndisplay(m)\n\n\n\n\n\n\n\n\n\n\nUsers may also reference ArcGIS Online item ID’s to import multiple layers with embedded symbology replacing the layer variable as noted above with gis.content.get().\nMany of the queries in this section are attributes acquired via calling the dir function in established Imagery Layers and building out attributes in a more sequential fashion but with many similar outputs to the requests section, building them via layer object attributes rather than hardcoding into a URL request.\nThis is shown as such in the plethora of capabilities listed in the below code:\n\nimport arcgis\n \nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer'\n \nlayer = arcgis.raster.ImageryLayer(url)\nprint(dir(layer))\n\n['__abs__', '__add__', '__and__', '__class__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_add_rasters', '_clone_layer', '_compute_multidimensional_info', '_con', '_datastore_raster', '_delete_rasters', '_extent', '_extent_set', '_filtered', '_fn', '_fnra', '_get_service_info', '_gis', '_hydrate', '_hydrated', '_ilm', '_invoke', '_lyr_dict', '_lyr_domains', '_lyr_json', '_mosaic_operation', '_mosaic_rule', '_original_info', '_other_outputs', '_raster_info', '_read_tilesonly_layer', '_refresh', '_rendering_rule_from_item', '_rendering_service_layer', '_rendering_service_object', '_repr_jpeg_', '_repr_svg_', '_spatial_filter', '_temporal_filter', '_tiles_only', '_time_filter', '_token', '_update_raster', '_upload', '_uri', '_url', '_uses_gbl_function', '_where_clause', 'attribute_table', 'band_count', 'blend', 'cache_manager', 'calculate_volume', 'catalog_item', 'colormap', 'columns', 'compute_angles', 'compute_cache_info', 'compute_class_stats', 'compute_histograms', 'compute_pixel_location', 'compute_stats_and_histograms', 'compute_tie_points', 'draw_graph', 'export_image', 'extent', 'filter', 'filter_by', 'filtered_rasters', 'first', 'fromitem', 'get_download_info', 'get_histograms', 'get_raster_file', 'get_samples', 'height', 'histograms', 'identify', 'item_info', 'key_properties', 'last', 'legend', 'max', 'mean', 'measure', 'metadata', 'min', 'mosaic_by', 'mosaic_rule', 'multidimensional_info', 'pixel_type', 'plot_histograms', 'project', 'properties', 'query', 'query_boundary', 'raster_info', 'rasters', 'render_tilesonly_layer', 'rows', 'save', 'service', 'set_filter', 'slices', 'spectral_profile', 'statistics', 'sum', 'temporal_profile', 'thumbnail', 'tiles', 'tiles_only', 'to_features', 'url', 'validate', 'width']\n\n\nFor example, users may parse through various slices, shown as the dictionary in the sample below:\n\nslice_list = layer.slices()['slices']\n \ndisplay(slice_list[0])\n\n{'sliceId': 0,\n 'multidimensionalDefinition': [{'variableName': 'CDD10',\n   'dimensionName': 'StdTime',\n   'values': [349747200000]}]}\n\n\nSlices and associated time slices for the Temperature at 2 Meters (T2M) variable can be loaded as follows:\n\nT2M_slices = {}\n \nimport datetime\nimport pandas as pd\n \nfor slice in slice_list:\n    #Stores underlying data in this particular service\n    multi_def = slice['multidimensionalDefinition'][0]\n    if multi_def['variableName'] == 'T2M':\n        Id = slice['sliceId']\n        time_epoch = multi_def['values'][0]\n        #Convert epoch time (e.g., 349747200000 to GMT)\n        GMT = datetime.datetime.fromtimestamp(time_epoch/1000)\n        T2M_slices[Id] = [time_epoch,GMT]\n         \ndf = pd.DataFrame.from_dict(T2M_slices,orient='index',columns=['Epoch Time','GMT Time'])\n \ndf.head()\n\n\n\n\n\n\n\n\nEpoch Time\nGMT Time\n\n\n\n\n8568\n349747200000\n1981-01-30 19:00:00\n\n\n8569\n352166400000\n1981-02-27 19:00:00\n\n\n8570\n354844800000\n1981-03-30 20:00:00\n\n\n8571\n357436800000\n1981-04-29 20:00:00\n\n\n8572\n360115200000\n1981-05-30 20:00:00\n\n\n\n\n\n\n\nNow that the data has been compiled into user-readable time stamps, let us combine all previous analyses to assess a variable at a given point for a few months of the year.\nWe start by categorizing each month into a set of slices:\n\ndf['Month'] = pd.DatetimeIndex(df['GMT Time']).month\ndf['Year'] = pd.DatetimeIndex(df['GMT Time']).year\n \nmonths = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nmonth_dict = {}\n \nfor i,month in enumerate(months,1):\n    month_dict[month] = df[df['Month'] == i].index.tolist()\n \nmonth_vis = pd.DataFrame.from_dict(month_dict,orient='index')\ndisplay(month_vis)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n\n\nJanuary\n8568\n8580\n8592\n8604\n8616\n8628\n8640\n8652\n8664\n8676\n...\n8952\n8964\n8976\n8988\n9000\n9012\n9024\n9036\n9048\n9060\n\n\nFebruary\n8569\n8581\n8593\n8605\n8617\n8629\n8641\n8653\n8665\n8677\n...\n8953\n8965\n8977\n8989\n9001\n9013\n9025\n9037\n9049\n9061\n\n\nMarch\n8570\n8582\n8594\n8606\n8618\n8630\n8642\n8654\n8666\n8678\n...\n8954\n8966\n8978\n8990\n9002\n9014\n9026\n9038\n9050\n9062\n\n\nApril\n8571\n8583\n8595\n8607\n8619\n8631\n8643\n8655\n8667\n8679\n...\n8955\n8967\n8979\n8991\n9003\n9015\n9027\n9039\n9051\n9063\n\n\nMay\n8572\n8584\n8596\n8608\n8620\n8632\n8644\n8656\n8668\n8680\n...\n8956\n8968\n8980\n8992\n9004\n9016\n9028\n9040\n9052\n9064\n\n\nJune\n8573\n8585\n8597\n8609\n8621\n8633\n8645\n8657\n8669\n8681\n...\n8957\n8969\n8981\n8993\n9005\n9017\n9029\n9041\n9053\n9065\n\n\nJuly\n8574\n8586\n8598\n8610\n8622\n8634\n8646\n8658\n8670\n8682\n...\n8958\n8970\n8982\n8994\n9006\n9018\n9030\n9042\n9054\n9066\n\n\nAugust\n8575\n8587\n8599\n8611\n8623\n8635\n8647\n8659\n8671\n8683\n...\n8959\n8971\n8983\n8995\n9007\n9019\n9031\n9043\n9055\n9067\n\n\nSeptember\n8576\n8588\n8600\n8612\n8624\n8636\n8648\n8660\n8672\n8684\n...\n8960\n8972\n8984\n8996\n9008\n9020\n9032\n9044\n9056\n9068\n\n\nOctober\n8577\n8589\n8601\n8613\n8625\n8637\n8649\n8661\n8673\n8685\n...\n8961\n8973\n8985\n8997\n9009\n9021\n9033\n9045\n9057\n9069\n\n\nNovember\n8578\n8590\n8602\n8614\n8626\n8638\n8650\n8662\n8674\n8686\n...\n8962\n8974\n8986\n8998\n9010\n9022\n9034\n9046\n9058\n9070\n\n\nDecember\n8579\n8591\n8603\n8615\n8627\n8639\n8651\n8663\n8675\n8687\n...\n8963\n8975\n8987\n8999\n9011\n9023\n9035\n9047\n9059\n9071\n\n\n\n\n12 rows × 42 columns\n\n\n\nFrom here, we establish a target latitude & longitude, under which we query specific time/variable slices and identify to the associated coordinate. TS (Earth Skin Temperature) is analyzed below temporally.\n\n\nlon = -41\nlat = 32\n \nlayer = arcgis.raster.ImageryLayer(url)\n \ntempdata = {}\n \nfor row in df.iterrows():\n    sliceId =row[0]\n    result = layer.identify(geometry={\"x\":lon,\"y\":lat},slice_id=sliceId)\n    result_C = float(result['value'])-273.15\n    tempdata[sliceId] = round(result_C,3)\n \ndf['Temp (C)'] = tempdata.values()\n \ndisplay(tempdata)\n\n{8568: 20.061,\n 8569: 19.014,\n 8570: 18.795,\n 8571: 18.577,\n 8572: 20.327,\n 8573: 22.803,\n 8574: 24.553,\n 8575: 25.272,\n 8576: 25.186,\n 8577: 23.975,\n 8578: 21.756,\n 8579: 20.78,\n 8580: 18.467,\n 8581: 18.155,\n 8582: 18.577,\n 8583: 18.467,\n 8584: 20.655,\n 8585: 22.709,\n 8586: 24.616,\n 8587: 25.42,\n 8588: 25.061,\n 8589: 24.616,\n 8590: 22.186,\n 8591: 20.717,\n 8592: 19.452,\n 8593: 18.655,\n 8594: 18.491,\n 8595: 18.944,\n 8596: 20.288,\n 8597: 22.288,\n 8598: 24.381,\n 8599: 25.303,\n 8600: 25.467,\n 8601: 23.616,\n 8602: 21.631,\n 8603: 19.678,\n 8604: 19.366,\n 8605: 18.491,\n 8606: 18.319,\n 8607: 19.194,\n 8608: 19.811,\n 8609: 22.014,\n 8610: 23.944,\n 8611: 24.866,\n 8612: 24.866,\n 8613: 24.17,\n 8614: 22.803,\n 8615: 20.936,\n 8616: 20.162,\n 8617: 18.28,\n 8618: 19.217,\n 8619: 19.108,\n 8620: 20.881,\n 8621: 22.522,\n 8622: 24.561,\n 8623: 25.538,\n 8624: 25.131,\n 8625: 22.67,\n 8626: 20.538,\n 8627: 19.217,\n 8628: 19.045,\n 8629: 18.873,\n 8630: 19.053,\n 8631: 19.334,\n 8632: 21.178,\n 8633: 23.116,\n 8634: 25.592,\n 8635: 26.123,\n 8636: 25.139,\n 8637: 23.694,\n 8638: 21.983,\n 8639: 20.373,\n 8640: 18.897,\n 8641: 18.952,\n 8642: 18.819,\n 8643: 18.959,\n 8644: 19.498,\n 8645: 22.186,\n 8646: 24.373,\n 8647: 25.78,\n 8648: 25.42,\n 8649: 23.655,\n 8650: 21.319,\n 8651: 20.225,\n 8652: 19.233,\n 8653: 18.428,\n 8654: 18.436,\n 8655: 19.038,\n 8656: 20.459,\n 8657: 22.475,\n 8658: 24.647,\n 8659: 26.389,\n 8660: 25.881,\n 8661: 24.553,\n 8662: 22.061,\n 8663: 19.944,\n 8664: 18.475,\n 8665: 18.975,\n 8666: 19.108,\n 8667: 20.014,\n 8668: 20.639,\n 8669: 22.975,\n 8670: 25.014,\n 8671: 25.897,\n 8672: 25.327,\n 8673: 24.03,\n 8674: 22.327,\n 8675: 21.1,\n 8676: 19.725,\n 8677: 18.295,\n 8678: 18.28,\n 8679: 18.78,\n 8680: 19.475,\n 8681: 22.475,\n 8682: 25.022,\n 8683: 25.389,\n 8684: 25.459,\n 8685: 23.928,\n 8686: 22.28,\n 8687: 20.592,\n 8688: 19.358,\n 8689: 19.592,\n 8690: 19.334,\n 8691: 19.1,\n 8692: 20.334,\n 8693: 23.483,\n 8694: 25.725,\n 8695: 26.819,\n 8696: 25.819,\n 8697: 23.975,\n 8698: 21.842,\n 8699: 20.452,\n 8700: 18.584,\n 8701: 19.092,\n 8702: 18.944,\n 8703: 19.686,\n 8704: 20.131,\n 8705: 22.155,\n 8706: 24.6,\n 8707: 26.069,\n 8708: 25.514,\n 8709: 23.35,\n 8710: 21.412,\n 8711: 20.561,\n 8712: 18.709,\n 8713: 18.662,\n 8714: 18.366,\n 8715: 19.467,\n 8716: 20.092,\n 8717: 22.811,\n 8718: 24.795,\n 8719: 25.717,\n 8720: 25.616,\n 8721: 23.709,\n 8722: 21.811,\n 8723: 20.459,\n 8724: 19.303,\n 8725: 18.569,\n 8726: 19.233,\n 8727: 19.123,\n 8728: 20.67,\n 8729: 22.725,\n 8730: 24.202,\n 8731: 25.827,\n 8732: 25.944,\n 8733: 24.725,\n 8734: 22.053,\n 8735: 20.912,\n 8736: 20.288,\n 8737: 19.858,\n 8738: 19.967,\n 8739: 19.53,\n 8740: 20.811,\n 8741: 21.85,\n 8742: 23.834,\n 8743: 25.756,\n 8744: 25.327,\n 8745: 23.108,\n 8746: 21.155,\n 8747: 20.217,\n 8748: 18.334,\n 8749: 18.358,\n 8750: 18.1,\n 8751: 18.92,\n 8752: 19.577,\n 8753: 21.717,\n 8754: 23.655,\n 8755: 25.288,\n 8756: 25.85,\n 8757: 24.741,\n 8758: 23.069,\n 8759: 20.475,\n 8760: 18.819,\n 8761: 18.03,\n 8762: 17.983,\n 8763: 18.514,\n 8764: 19.623,\n 8765: 21.873,\n 8766: 24.842,\n 8767: 26.209,\n 8768: 25.647,\n 8769: 23.655,\n 8770: 21.795,\n 8771: 20.686,\n 8772: 18.655,\n 8773: 17.67,\n 8774: 18.03,\n 8775: 19.358,\n 8776: 20.741,\n 8777: 22.795,\n 8778: 24.608,\n 8779: 25.983,\n 8780: 26.553,\n 8781: 24.764,\n 8782: 23.327,\n 8783: 20.889,\n 8784: 19.788,\n 8785: 18.866,\n 8786: 19.397,\n 8787: 20.162,\n 8788: 21.045,\n 8789: 22.358,\n 8790: 25.123,\n 8791: 26.42,\n 8792: 26.209,\n 8793: 24.858,\n 8794: 22.444,\n 8795: 21.366,\n 8796: 19.678,\n 8797: 19.584,\n 8798: 18.967,\n 8799: 19.264,\n 8800: 21.405,\n 8801: 23.092,\n 8802: 24.866,\n 8803: 25.506,\n 8804: 25.702,\n 8805: 25.014,\n 8806: 23.319,\n 8807: 20.834,\n 8808: 20.209,\n 8809: 18.545,\n 8810: 18.608,\n 8811: 19.397,\n 8812: 20.467,\n 8813: 22.022,\n 8814: 24.584,\n 8815: 26.366,\n 8816: 25.366,\n 8817: 24.061,\n 8818: 22.702,\n 8819: 19.733,\n 8820: 18.811,\n 8821: 19.053,\n 8822: 17.795,\n 8823: 19.069,\n 8824: 21.038,\n 8825: 22.694,\n 8826: 24.186,\n 8827: 25.28,\n 8828: 25.334,\n 8829: 23.842,\n 8830: 22.334,\n 8831: 20.881,\n 8832: 20.092,\n 8833: 19.569,\n 8834: 18.662,\n 8835: 18.381,\n 8836: 20.827,\n 8837: 23.303,\n 8838: 25.717,\n 8839: 26.28,\n 8840: 25.295,\n 8841: 23.381,\n 8842: 22.084,\n 8843: 20.725,\n 8844: 20.092,\n 8845: 17.998,\n 8846: 18.788,\n 8847: 19.108,\n 8848: 19.788,\n 8849: 22.584,\n 8850: 24.319,\n 8851: 25.623,\n 8852: 25.381,\n 8853: 23.936,\n 8854: 22.288,\n 8855: 21.217,\n 8856: 19.912,\n 8857: 19.592,\n 8858: 18.522,\n 8859: 19.186,\n 8860: 19.936,\n 8861: 22.319,\n 8862: 24.358,\n 8863: 25.655,\n 8864: 25.483,\n 8865: 24.1,\n 8866: 22.686,\n 8867: 20.631,\n 8868: 19.639,\n 8869: 19.35,\n 8870: 19.506,\n 8871: 19.014,\n 8872: 20.452,\n 8873: 21.514,\n 8874: 23.748,\n 8875: 25.639,\n 8876: 25.256,\n 8877: 23.998,\n 8878: 21.561,\n 8879: 19.912,\n 8880: 19.084,\n 8881: 19.428,\n 8882: 19.764,\n 8883: 19.709,\n 8884: 21.577,\n 8885: 22.983,\n 8886: 24.741,\n 8887: 25.483,\n 8888: 25.225,\n 8889: 23.694,\n 8890: 21.748,\n 8891: 20.873,\n 8892: 19.584,\n 8893: 18.498,\n 8894: 18.803,\n 8895: 19.084,\n 8896: 21.295,\n 8897: 22.811,\n 8898: 24.53,\n 8899: 26.178,\n 8900: 25.873,\n 8901: 24.827,\n 8902: 22.358,\n 8903: 20.592,\n 8904: 20.053,\n 8905: 18.803,\n 8906: 19.17,\n 8907: 19.756,\n 8908: 20.577,\n 8909: 22.92,\n 8910: 24.858,\n 8911: 26.17,\n 8912: 25.647,\n 8913: 23.78,\n 8914: 22.178,\n 8915: 19.873,\n 8916: 18.764,\n 8917: 17.983,\n 8918: 17.748,\n 8919: 18.795,\n 8920: 20.038,\n 8921: 22.631,\n 8922: 25.116,\n 8923: 26.03,\n 8924: 25.459,\n 8925: 24.467,\n 8926: 22.592,\n 8927: 19.662,\n 8928: 18.912,\n 8929: 19.006,\n 8930: 18.35,\n 8931: 18.123,\n 8932: 20.202,\n 8933: 22.788,\n 8934: 24.381,\n 8935: 25.412,\n 8936: 25.647,\n 8937: 23.67,\n 8938: 21.647,\n 8939: 21.123,\n 8940: 19.366,\n 8941: 19.077,\n 8942: 18.538,\n 8943: 19.756,\n 8944: 19.858,\n 8945: 23.209,\n 8946: 24.202,\n 8947: 26.295,\n 8948: 25.139,\n 8949: 23.272,\n 8950: 21.741,\n 8951: 20.209,\n 8952: 19.256,\n 8953: 18.631,\n 8954: 18.662,\n 8955: 18.069,\n 8956: 19.53,\n 8957: 22.233,\n 8958: 24.912,\n 8959: 25.858,\n 8960: 25.756,\n 8961: 24.139,\n 8962: 23.1,\n 8963: 20.553,\n 8964: 19.741,\n 8965: 19.405,\n 8966: 19.741,\n 8967: 19.038,\n 8968: 20.631,\n 8969: 22.788,\n 8970: 24.631,\n 8971: 26.241,\n 8972: 25.483,\n 8973: 24.17,\n 8974: 22.264,\n 8975: 21.045,\n 8976: 19.897,\n 8977: 19.444,\n 8978: 19.639,\n 8979: 19.428,\n 8980: 20.256,\n 8981: 22.959,\n 8982: 25.389,\n 8983: 25.834,\n 8984: 25.498,\n 8985: 24.03,\n 8986: 22.577,\n 8987: 20.077,\n 8988: 19.866,\n 8989: 19.303,\n 8990: 19.139,\n 8991: 19.303,\n 8992: 20.944,\n 8993: 22.85,\n 8994: 24.452,\n 8995: 25.694,\n 8996: 25.444,\n 8997: 24.061,\n 8998: 22.897,\n 8999: 20.803,\n 9000: 19.381,\n 9001: 19.842,\n 9002: 18.912,\n 9003: 19.397,\n 9004: 19.725,\n 9005: 22.334,\n 9006: 24.538,\n 9007: 26.42,\n 9008: 25.569,\n 9009: 23.639,\n 9010: 22.116,\n 9011: 21.17,\n 9012: 20.155,\n 9013: 18.764,\n 9014: 19.592,\n 9015: 19.35,\n 9016: 21.256,\n 9017: 23.78,\n 9018: 24.436,\n 9019: 25.389,\n 9020: 25.561,\n 9021: 23.975,\n 9022: 22.538,\n 9023: 20.748,\n 9024: 19.397,\n 9025: 18.905,\n 9026: 19.584,\n 9027: 19.498,\n 9028: 20.709,\n 9029: 22.881,\n 9030: 25.334,\n 9031: 26.491,\n 9032: 26.225,\n 9033: 23.717,\n 9034: 22.514,\n 9035: 21.225,\n 9036: 19.967,\n 9037: 19.397,\n 9038: 19.397,\n 9039: 19.975,\n 9040: 20.686,\n 9041: 21.936,\n 9042: 24.655,\n 9043: 26.811,\n 9044: 25.889,\n 9045: 24.342,\n 9046: 22.538,\n 9047: 21.342,\n 9048: 20.944,\n 9049: 18.912,\n 9050: 18.866,\n 9051: 19.444,\n 9052: 21.866,\n 9053: 22.889,\n 9054: 24.975,\n 9055: 25.889,\n 9056: 25.694,\n 9057: 24.647,\n 9058: 22.491,\n 9059: 20.756,\n 9060: 18.569,\n 9061: 18.522,\n 9062: 18.998,\n 9063: 19.131,\n 9064: 20.319,\n 9065: 22.873,\n 9066: 24.186,\n 9067: 26.116,\n 9068: 26.295,\n 9069: 24.647,\n 9070: 23.139,\n 9071: 20.772}\n\n\nWe will now extract March to July data into separate series to be plotted:\n\nimport matplotlib.pyplot as plt\n \nxpoints = list(set(df['Year'].tolist()))\n \nfor ind,monthname in enumerate(months[2:6],3):\n    plt.plot(xpoints,df[df['Month']==ind]['Temp (C)'],label=monthname)\n     \nplt.show()"
  },
  {
    "objectID": "tutorials/getting-started-arcgis.html#requests",
    "href": "tutorials/getting-started-arcgis.html#requests",
    "title": "Getting Started with Image Services",
    "section": "",
    "text": "The built-in library requests allows the user to programmatically access many of the underlying REST service interface capabilities such as statistics, image export, histograms, or slices. For example, users can acquire various statistics in specific fields in JSON format:\n\nimport requests\nimport pandas as pd\n \nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/multiDimensionalInfo?returnDimensionValues=always&f=pjson'\nr = requests.get(url)\n \noutDict = {}\n \nfor variable_dict in r.json()['multidimensionalInfo']['variables']:\n    outDict[variable_dict['name']] = [variable_dict['attributes']['standard_name'],variable_dict['unit']]\n \ndisplay(pd.DataFrame.from_dict(outDict,orient='index',columns=['Long Name','Unit of Measurement']))\n\n\n\n\n\n\n\n\nLong Name\nUnit of Measurement\n\n\n\n\nCDD10\nCooling_Degree_Days_Above_10_C\ndegree-day\n\n\nCDD18_3\nCooling_Degree_Days_Above_18.3_C\ndegree-day\n\n\nDISPH\nZero_Plane_Displacement_Height\nm\n\n\nEVLAND\nEvaporation_Land\nkg m-2 s-1\n\n\nEVPTRNS\nEvapotranspiration_Energy_Flux\nW m-2\n\n\nFROST_DAYS\nFrost_Days\ndays\n\n\nGWETTOP\nSurface_Soil_Wetness\n1\n\n\nHDD10\nHeating_Degree_Days_Below_10_C\ndegree-day\n\n\nHDD18_3\nHeating_Degree_Days_Below_18.3_C\ndegree-day\n\n\nPBLTOP\nPlanetary_Boundary_Layer_Top_Pressure\nPa\n\n\nPRECSNOLAND_SUM\nSnow_Precipitation_Land_Sum\nkg m-2 s-1\n\n\nPRECTOTCORR_SUM\nPrecipitation_Corrected_Sum\nkg m-2 s-1\n\n\nPS\nSurface_Pressure\nPa\n\n\nQV10M\nSpecific_Humidity_at_10_Meters\nkg/kg\n\n\nQV2M\nSpecific_Humidity_at_2_Meters\nkg/kg\n\n\nRH2M\nRelative_Humidity_at_2_Meters\n%\n\n\nT10M\nTemperature_at_10_Meters\nK\n\n\nT2M\nTemperature_at_2_Meters\nK\n\n\nT2MDEW\nDew/Frost_Point_at_2_Meters\nK\n\n\nT2MWET\nWet_Bulb_Temperature_at_2_Meters\nK\n\n\nTO3\nTotal_Column_Ozone\nDobsons\n\n\nTQV\nTotal_Column_Precipitable_Water\nkg m-2\n\n\nTS\nEarth_Skin_Temperature\nK\n\n\nWD10M\nWind_Direction_at_10_Meters\nDegrees\n\n\nWD2M\nWind_Direction_at_2_Meters\nDegrees\n\n\nWD50M\nWind_Direction_at_50_Meters\nDegrees\n\n\nWS10M\nWind_Speed_at_10_Meters\nm/s\n\n\nWS2M\nWind_Speed_at_2_Meters\nm/s\n\n\nWS50M\nWind_Speed_at_50_Meters\nm/s\n\n\n\n\n\n\n\n\nt2m_url = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/statistics?variable=T2M&renderingRule=&f=pjson'\nr_t2m = requests.get(t2m_url)\n \nstats = r_t2m.json()['statistics'][0]\ndisplay(stats)\n\n{'min': 199.078125,\n 'max': 314.9453125,\n 'mean': 278.25700790851954,\n 'standardDeviation': 21.776876164664852,\n 'median': 282.22987132352944,\n 'mode': 299.49635416666666,\n 'skipX': 1,\n 'skipY': 1,\n 'count': 130999680}\n\n\nSimilarly, querying this variable can show what slice identifiers correspond to this variable. Queries on specific points for slices can be browsed on the slices capability pane. A sample is shown below:\n\nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/slices?multidimensionalDefinition=%7B%22variableName%22%3A%22T2M%22%7D&f=json'\n \nr = requests.get(url)\ndisplay(r.json()['slices'][25:55])\n \n#'Values' dictionary list indices indicate epoch time; e.g., 415490850000 indicates Wednesday, March 2, 1983 10:07:30 PM GMT (per &lt;https://www.epochconverter.com/&gt;)\n\n[{'sliceId': 8593,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [415238400000]}]},\n {'sliceId': 8594,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [417916800000]}]},\n {'sliceId': 8595,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [420508800000]}]},\n {'sliceId': 8596,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [423187200000]}]},\n {'sliceId': 8597,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [425779200000]}]},\n {'sliceId': 8598,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [428457600000]}]},\n {'sliceId': 8599,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [431136000000]}]},\n {'sliceId': 8600,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [433728000000]}]},\n {'sliceId': 8601,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [436406400000]}]},\n {'sliceId': 8602,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [438998400000]}]},\n {'sliceId': 8603,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [441676800000]}]},\n {'sliceId': 8604,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [444355200000]}]},\n {'sliceId': 8605,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [446860800000]}]},\n {'sliceId': 8606,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [449539200000]}]},\n {'sliceId': 8607,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [452131200000]}]},\n {'sliceId': 8608,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [454809600000]}]},\n {'sliceId': 8609,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [457401600000]}]},\n {'sliceId': 8610,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [460080000000]}]},\n {'sliceId': 8611,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [462758400000]}]},\n {'sliceId': 8612,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [465350400000]}]},\n {'sliceId': 8613,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [468028800000]}]},\n {'sliceId': 8614,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [470620800000]}]},\n {'sliceId': 8615,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [473299200000]}]},\n {'sliceId': 8616,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [475977600000]}]},\n {'sliceId': 8617,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [478396800000]}]},\n {'sliceId': 8618,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [481075200000]}]},\n {'sliceId': 8619,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [483667200000]}]},\n {'sliceId': 8620,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [486345600000]}]},\n {'sliceId': 8621,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [488937600000]}]},\n {'sliceId': 8622,\n  'multidimensionalDefinition': [{'variableName': 'T2M',\n    'dimensionName': 'StdTime',\n    'values': [491616000000]}]}]\n\n\nFinally, by browsing this REST endpoint capability or parsing it via JSON, a user can query a specific coordinate (100,50) for August 2nd, 1983 (slice 50, epoch time 428639580000):\n\nfrom IPython.display import Markdown\n \nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/identify?geometry=%7B%22x%22%3A100%2C%22y%22%3A50%7D&geometryType=esriGeometryPoint&mosaicRule=&renderingRule=&renderingRules=&pixelSize=&sliceId=1950&time=&returnGeometry=true&returnCatalogItems=true&returnPixelValues=true&processAsMultidimensional=true&maxItemCount=10&f=pjson'\n \nr = requests.get(url)\ndisplay(Markdown(\"*Sample requests JSON response:*\"))\ndisplay(r.json())\n \nvalue = r.json()['value'].split('.')[0]\nMarkdown(f\"**Query result:** {value} K\")\nr = requests.get(r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer/statistics?variable=T2M&renderingRule=&f=pjson')\ntemp_min = r.json()['statistics'][0]['min']\n\nSample requests JSON response:\n\n\n{'objectId': 0,\n 'name': 'Pixel',\n 'value': '2.28882e-05',\n 'location': {'x': 100,\n  'y': 50,\n  'spatialReference': {'wkid': 4326, 'latestWkid': 4326}},\n 'properties': {'Attributes': [{'Variable': 'EVLAND',\n    'StdTime': 1501459200000,\n    'StdTime_Max': 1501459200000}]},\n 'catalogItems': None,\n 'catalogItemVisibilities': []}"
  },
  {
    "objectID": "tutorials/getting-started-arcgis.html#arcgis-api-for-python",
    "href": "tutorials/getting-started-arcgis.html#arcgis-api-for-python",
    "title": "Getting Started with Image Services",
    "section": "",
    "text": "Users may perform much of the same functionality in web maps and in desktop software using Esri-developed Python packages arcpy and arcgis. This section of the tutorial will focus on the freely available online arcgis module which can be used easily in Esri’s Experience Builder, Jupyter notebooks, or across a wide variety of programming and web environments and use cases.\nThe below examples use the GPM and POWER image services.\nA user can import a give Image Service into a web map as follows utilizing the arcgis.mapping utilities to generate a custom map:\n\nimport arcgis\n \nm = arcgis.mapping.WebMap()\n \nGPM_url = r'https://arcgis.gesdisc.eosdis.nasa.gov/authoritative/rest/services/GPM_3IMERGHHE_06/ImageServer'\n \nlayer = arcgis.raster.ImageryLayer(GPM_url)\nm.add_layer(layer)\ndisplay(m)\n\n\n\n\n\n\n\n\n\n\nUsers may also reference ArcGIS Online item ID’s to import multiple layers with embedded symbology replacing the layer variable as noted above with gis.content.get().\nMany of the queries in this section are attributes acquired via calling the dir function in established Imagery Layers and building out attributes in a more sequential fashion but with many similar outputs to the requests section, building them via layer object attributes rather than hardcoding into a URL request.\nThis is shown as such in the plethora of capabilities listed in the below code:\n\nimport arcgis\n \nurl = r'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_MONTHLY_METEOROLOGY_UTC/ImageServer'\n \nlayer = arcgis.raster.ImageryLayer(url)\nprint(dir(layer))\n\n['__abs__', '__add__', '__and__', '__class__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_add_rasters', '_clone_layer', '_compute_multidimensional_info', '_con', '_datastore_raster', '_delete_rasters', '_extent', '_extent_set', '_filtered', '_fn', '_fnra', '_get_service_info', '_gis', '_hydrate', '_hydrated', '_ilm', '_invoke', '_lyr_dict', '_lyr_domains', '_lyr_json', '_mosaic_operation', '_mosaic_rule', '_original_info', '_other_outputs', '_raster_info', '_read_tilesonly_layer', '_refresh', '_rendering_rule_from_item', '_rendering_service_layer', '_rendering_service_object', '_repr_jpeg_', '_repr_svg_', '_spatial_filter', '_temporal_filter', '_tiles_only', '_time_filter', '_token', '_update_raster', '_upload', '_uri', '_url', '_uses_gbl_function', '_where_clause', 'attribute_table', 'band_count', 'blend', 'cache_manager', 'calculate_volume', 'catalog_item', 'colormap', 'columns', 'compute_angles', 'compute_cache_info', 'compute_class_stats', 'compute_histograms', 'compute_pixel_location', 'compute_stats_and_histograms', 'compute_tie_points', 'draw_graph', 'export_image', 'extent', 'filter', 'filter_by', 'filtered_rasters', 'first', 'fromitem', 'get_download_info', 'get_histograms', 'get_raster_file', 'get_samples', 'height', 'histograms', 'identify', 'item_info', 'key_properties', 'last', 'legend', 'max', 'mean', 'measure', 'metadata', 'min', 'mosaic_by', 'mosaic_rule', 'multidimensional_info', 'pixel_type', 'plot_histograms', 'project', 'properties', 'query', 'query_boundary', 'raster_info', 'rasters', 'render_tilesonly_layer', 'rows', 'save', 'service', 'set_filter', 'slices', 'spectral_profile', 'statistics', 'sum', 'temporal_profile', 'thumbnail', 'tiles', 'tiles_only', 'to_features', 'url', 'validate', 'width']\n\n\nFor example, users may parse through various slices, shown as the dictionary in the sample below:\n\nslice_list = layer.slices()['slices']\n \ndisplay(slice_list[0])\n\n{'sliceId': 0,\n 'multidimensionalDefinition': [{'variableName': 'CDD10',\n   'dimensionName': 'StdTime',\n   'values': [349747200000]}]}\n\n\nSlices and associated time slices for the Temperature at 2 Meters (T2M) variable can be loaded as follows:\n\nT2M_slices = {}\n \nimport datetime\nimport pandas as pd\n \nfor slice in slice_list:\n    #Stores underlying data in this particular service\n    multi_def = slice['multidimensionalDefinition'][0]\n    if multi_def['variableName'] == 'T2M':\n        Id = slice['sliceId']\n        time_epoch = multi_def['values'][0]\n        #Convert epoch time (e.g., 349747200000 to GMT)\n        GMT = datetime.datetime.fromtimestamp(time_epoch/1000)\n        T2M_slices[Id] = [time_epoch,GMT]\n         \ndf = pd.DataFrame.from_dict(T2M_slices,orient='index',columns=['Epoch Time','GMT Time'])\n \ndf.head()\n\n\n\n\n\n\n\n\nEpoch Time\nGMT Time\n\n\n\n\n8568\n349747200000\n1981-01-30 19:00:00\n\n\n8569\n352166400000\n1981-02-27 19:00:00\n\n\n8570\n354844800000\n1981-03-30 20:00:00\n\n\n8571\n357436800000\n1981-04-29 20:00:00\n\n\n8572\n360115200000\n1981-05-30 20:00:00\n\n\n\n\n\n\n\nNow that the data has been compiled into user-readable time stamps, let us combine all previous analyses to assess a variable at a given point for a few months of the year.\nWe start by categorizing each month into a set of slices:\n\ndf['Month'] = pd.DatetimeIndex(df['GMT Time']).month\ndf['Year'] = pd.DatetimeIndex(df['GMT Time']).year\n \nmonths = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nmonth_dict = {}\n \nfor i,month in enumerate(months,1):\n    month_dict[month] = df[df['Month'] == i].index.tolist()\n \nmonth_vis = pd.DataFrame.from_dict(month_dict,orient='index')\ndisplay(month_vis)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n\n\nJanuary\n8568\n8580\n8592\n8604\n8616\n8628\n8640\n8652\n8664\n8676\n...\n8952\n8964\n8976\n8988\n9000\n9012\n9024\n9036\n9048\n9060\n\n\nFebruary\n8569\n8581\n8593\n8605\n8617\n8629\n8641\n8653\n8665\n8677\n...\n8953\n8965\n8977\n8989\n9001\n9013\n9025\n9037\n9049\n9061\n\n\nMarch\n8570\n8582\n8594\n8606\n8618\n8630\n8642\n8654\n8666\n8678\n...\n8954\n8966\n8978\n8990\n9002\n9014\n9026\n9038\n9050\n9062\n\n\nApril\n8571\n8583\n8595\n8607\n8619\n8631\n8643\n8655\n8667\n8679\n...\n8955\n8967\n8979\n8991\n9003\n9015\n9027\n9039\n9051\n9063\n\n\nMay\n8572\n8584\n8596\n8608\n8620\n8632\n8644\n8656\n8668\n8680\n...\n8956\n8968\n8980\n8992\n9004\n9016\n9028\n9040\n9052\n9064\n\n\nJune\n8573\n8585\n8597\n8609\n8621\n8633\n8645\n8657\n8669\n8681\n...\n8957\n8969\n8981\n8993\n9005\n9017\n9029\n9041\n9053\n9065\n\n\nJuly\n8574\n8586\n8598\n8610\n8622\n8634\n8646\n8658\n8670\n8682\n...\n8958\n8970\n8982\n8994\n9006\n9018\n9030\n9042\n9054\n9066\n\n\nAugust\n8575\n8587\n8599\n8611\n8623\n8635\n8647\n8659\n8671\n8683\n...\n8959\n8971\n8983\n8995\n9007\n9019\n9031\n9043\n9055\n9067\n\n\nSeptember\n8576\n8588\n8600\n8612\n8624\n8636\n8648\n8660\n8672\n8684\n...\n8960\n8972\n8984\n8996\n9008\n9020\n9032\n9044\n9056\n9068\n\n\nOctober\n8577\n8589\n8601\n8613\n8625\n8637\n8649\n8661\n8673\n8685\n...\n8961\n8973\n8985\n8997\n9009\n9021\n9033\n9045\n9057\n9069\n\n\nNovember\n8578\n8590\n8602\n8614\n8626\n8638\n8650\n8662\n8674\n8686\n...\n8962\n8974\n8986\n8998\n9010\n9022\n9034\n9046\n9058\n9070\n\n\nDecember\n8579\n8591\n8603\n8615\n8627\n8639\n8651\n8663\n8675\n8687\n...\n8963\n8975\n8987\n8999\n9011\n9023\n9035\n9047\n9059\n9071\n\n\n\n\n12 rows × 42 columns\n\n\n\nFrom here, we establish a target latitude & longitude, under which we query specific time/variable slices and identify to the associated coordinate. TS (Earth Skin Temperature) is analyzed below temporally.\n\n\nlon = -41\nlat = 32\n \nlayer = arcgis.raster.ImageryLayer(url)\n \ntempdata = {}\n \nfor row in df.iterrows():\n    sliceId =row[0]\n    result = layer.identify(geometry={\"x\":lon,\"y\":lat},slice_id=sliceId)\n    result_C = float(result['value'])-273.15\n    tempdata[sliceId] = round(result_C,3)\n \ndf['Temp (C)'] = tempdata.values()\n \ndisplay(tempdata)\n\n{8568: 20.061,\n 8569: 19.014,\n 8570: 18.795,\n 8571: 18.577,\n 8572: 20.327,\n 8573: 22.803,\n 8574: 24.553,\n 8575: 25.272,\n 8576: 25.186,\n 8577: 23.975,\n 8578: 21.756,\n 8579: 20.78,\n 8580: 18.467,\n 8581: 18.155,\n 8582: 18.577,\n 8583: 18.467,\n 8584: 20.655,\n 8585: 22.709,\n 8586: 24.616,\n 8587: 25.42,\n 8588: 25.061,\n 8589: 24.616,\n 8590: 22.186,\n 8591: 20.717,\n 8592: 19.452,\n 8593: 18.655,\n 8594: 18.491,\n 8595: 18.944,\n 8596: 20.288,\n 8597: 22.288,\n 8598: 24.381,\n 8599: 25.303,\n 8600: 25.467,\n 8601: 23.616,\n 8602: 21.631,\n 8603: 19.678,\n 8604: 19.366,\n 8605: 18.491,\n 8606: 18.319,\n 8607: 19.194,\n 8608: 19.811,\n 8609: 22.014,\n 8610: 23.944,\n 8611: 24.866,\n 8612: 24.866,\n 8613: 24.17,\n 8614: 22.803,\n 8615: 20.936,\n 8616: 20.162,\n 8617: 18.28,\n 8618: 19.217,\n 8619: 19.108,\n 8620: 20.881,\n 8621: 22.522,\n 8622: 24.561,\n 8623: 25.538,\n 8624: 25.131,\n 8625: 22.67,\n 8626: 20.538,\n 8627: 19.217,\n 8628: 19.045,\n 8629: 18.873,\n 8630: 19.053,\n 8631: 19.334,\n 8632: 21.178,\n 8633: 23.116,\n 8634: 25.592,\n 8635: 26.123,\n 8636: 25.139,\n 8637: 23.694,\n 8638: 21.983,\n 8639: 20.373,\n 8640: 18.897,\n 8641: 18.952,\n 8642: 18.819,\n 8643: 18.959,\n 8644: 19.498,\n 8645: 22.186,\n 8646: 24.373,\n 8647: 25.78,\n 8648: 25.42,\n 8649: 23.655,\n 8650: 21.319,\n 8651: 20.225,\n 8652: 19.233,\n 8653: 18.428,\n 8654: 18.436,\n 8655: 19.038,\n 8656: 20.459,\n 8657: 22.475,\n 8658: 24.647,\n 8659: 26.389,\n 8660: 25.881,\n 8661: 24.553,\n 8662: 22.061,\n 8663: 19.944,\n 8664: 18.475,\n 8665: 18.975,\n 8666: 19.108,\n 8667: 20.014,\n 8668: 20.639,\n 8669: 22.975,\n 8670: 25.014,\n 8671: 25.897,\n 8672: 25.327,\n 8673: 24.03,\n 8674: 22.327,\n 8675: 21.1,\n 8676: 19.725,\n 8677: 18.295,\n 8678: 18.28,\n 8679: 18.78,\n 8680: 19.475,\n 8681: 22.475,\n 8682: 25.022,\n 8683: 25.389,\n 8684: 25.459,\n 8685: 23.928,\n 8686: 22.28,\n 8687: 20.592,\n 8688: 19.358,\n 8689: 19.592,\n 8690: 19.334,\n 8691: 19.1,\n 8692: 20.334,\n 8693: 23.483,\n 8694: 25.725,\n 8695: 26.819,\n 8696: 25.819,\n 8697: 23.975,\n 8698: 21.842,\n 8699: 20.452,\n 8700: 18.584,\n 8701: 19.092,\n 8702: 18.944,\n 8703: 19.686,\n 8704: 20.131,\n 8705: 22.155,\n 8706: 24.6,\n 8707: 26.069,\n 8708: 25.514,\n 8709: 23.35,\n 8710: 21.412,\n 8711: 20.561,\n 8712: 18.709,\n 8713: 18.662,\n 8714: 18.366,\n 8715: 19.467,\n 8716: 20.092,\n 8717: 22.811,\n 8718: 24.795,\n 8719: 25.717,\n 8720: 25.616,\n 8721: 23.709,\n 8722: 21.811,\n 8723: 20.459,\n 8724: 19.303,\n 8725: 18.569,\n 8726: 19.233,\n 8727: 19.123,\n 8728: 20.67,\n 8729: 22.725,\n 8730: 24.202,\n 8731: 25.827,\n 8732: 25.944,\n 8733: 24.725,\n 8734: 22.053,\n 8735: 20.912,\n 8736: 20.288,\n 8737: 19.858,\n 8738: 19.967,\n 8739: 19.53,\n 8740: 20.811,\n 8741: 21.85,\n 8742: 23.834,\n 8743: 25.756,\n 8744: 25.327,\n 8745: 23.108,\n 8746: 21.155,\n 8747: 20.217,\n 8748: 18.334,\n 8749: 18.358,\n 8750: 18.1,\n 8751: 18.92,\n 8752: 19.577,\n 8753: 21.717,\n 8754: 23.655,\n 8755: 25.288,\n 8756: 25.85,\n 8757: 24.741,\n 8758: 23.069,\n 8759: 20.475,\n 8760: 18.819,\n 8761: 18.03,\n 8762: 17.983,\n 8763: 18.514,\n 8764: 19.623,\n 8765: 21.873,\n 8766: 24.842,\n 8767: 26.209,\n 8768: 25.647,\n 8769: 23.655,\n 8770: 21.795,\n 8771: 20.686,\n 8772: 18.655,\n 8773: 17.67,\n 8774: 18.03,\n 8775: 19.358,\n 8776: 20.741,\n 8777: 22.795,\n 8778: 24.608,\n 8779: 25.983,\n 8780: 26.553,\n 8781: 24.764,\n 8782: 23.327,\n 8783: 20.889,\n 8784: 19.788,\n 8785: 18.866,\n 8786: 19.397,\n 8787: 20.162,\n 8788: 21.045,\n 8789: 22.358,\n 8790: 25.123,\n 8791: 26.42,\n 8792: 26.209,\n 8793: 24.858,\n 8794: 22.444,\n 8795: 21.366,\n 8796: 19.678,\n 8797: 19.584,\n 8798: 18.967,\n 8799: 19.264,\n 8800: 21.405,\n 8801: 23.092,\n 8802: 24.866,\n 8803: 25.506,\n 8804: 25.702,\n 8805: 25.014,\n 8806: 23.319,\n 8807: 20.834,\n 8808: 20.209,\n 8809: 18.545,\n 8810: 18.608,\n 8811: 19.397,\n 8812: 20.467,\n 8813: 22.022,\n 8814: 24.584,\n 8815: 26.366,\n 8816: 25.366,\n 8817: 24.061,\n 8818: 22.702,\n 8819: 19.733,\n 8820: 18.811,\n 8821: 19.053,\n 8822: 17.795,\n 8823: 19.069,\n 8824: 21.038,\n 8825: 22.694,\n 8826: 24.186,\n 8827: 25.28,\n 8828: 25.334,\n 8829: 23.842,\n 8830: 22.334,\n 8831: 20.881,\n 8832: 20.092,\n 8833: 19.569,\n 8834: 18.662,\n 8835: 18.381,\n 8836: 20.827,\n 8837: 23.303,\n 8838: 25.717,\n 8839: 26.28,\n 8840: 25.295,\n 8841: 23.381,\n 8842: 22.084,\n 8843: 20.725,\n 8844: 20.092,\n 8845: 17.998,\n 8846: 18.788,\n 8847: 19.108,\n 8848: 19.788,\n 8849: 22.584,\n 8850: 24.319,\n 8851: 25.623,\n 8852: 25.381,\n 8853: 23.936,\n 8854: 22.288,\n 8855: 21.217,\n 8856: 19.912,\n 8857: 19.592,\n 8858: 18.522,\n 8859: 19.186,\n 8860: 19.936,\n 8861: 22.319,\n 8862: 24.358,\n 8863: 25.655,\n 8864: 25.483,\n 8865: 24.1,\n 8866: 22.686,\n 8867: 20.631,\n 8868: 19.639,\n 8869: 19.35,\n 8870: 19.506,\n 8871: 19.014,\n 8872: 20.452,\n 8873: 21.514,\n 8874: 23.748,\n 8875: 25.639,\n 8876: 25.256,\n 8877: 23.998,\n 8878: 21.561,\n 8879: 19.912,\n 8880: 19.084,\n 8881: 19.428,\n 8882: 19.764,\n 8883: 19.709,\n 8884: 21.577,\n 8885: 22.983,\n 8886: 24.741,\n 8887: 25.483,\n 8888: 25.225,\n 8889: 23.694,\n 8890: 21.748,\n 8891: 20.873,\n 8892: 19.584,\n 8893: 18.498,\n 8894: 18.803,\n 8895: 19.084,\n 8896: 21.295,\n 8897: 22.811,\n 8898: 24.53,\n 8899: 26.178,\n 8900: 25.873,\n 8901: 24.827,\n 8902: 22.358,\n 8903: 20.592,\n 8904: 20.053,\n 8905: 18.803,\n 8906: 19.17,\n 8907: 19.756,\n 8908: 20.577,\n 8909: 22.92,\n 8910: 24.858,\n 8911: 26.17,\n 8912: 25.647,\n 8913: 23.78,\n 8914: 22.178,\n 8915: 19.873,\n 8916: 18.764,\n 8917: 17.983,\n 8918: 17.748,\n 8919: 18.795,\n 8920: 20.038,\n 8921: 22.631,\n 8922: 25.116,\n 8923: 26.03,\n 8924: 25.459,\n 8925: 24.467,\n 8926: 22.592,\n 8927: 19.662,\n 8928: 18.912,\n 8929: 19.006,\n 8930: 18.35,\n 8931: 18.123,\n 8932: 20.202,\n 8933: 22.788,\n 8934: 24.381,\n 8935: 25.412,\n 8936: 25.647,\n 8937: 23.67,\n 8938: 21.647,\n 8939: 21.123,\n 8940: 19.366,\n 8941: 19.077,\n 8942: 18.538,\n 8943: 19.756,\n 8944: 19.858,\n 8945: 23.209,\n 8946: 24.202,\n 8947: 26.295,\n 8948: 25.139,\n 8949: 23.272,\n 8950: 21.741,\n 8951: 20.209,\n 8952: 19.256,\n 8953: 18.631,\n 8954: 18.662,\n 8955: 18.069,\n 8956: 19.53,\n 8957: 22.233,\n 8958: 24.912,\n 8959: 25.858,\n 8960: 25.756,\n 8961: 24.139,\n 8962: 23.1,\n 8963: 20.553,\n 8964: 19.741,\n 8965: 19.405,\n 8966: 19.741,\n 8967: 19.038,\n 8968: 20.631,\n 8969: 22.788,\n 8970: 24.631,\n 8971: 26.241,\n 8972: 25.483,\n 8973: 24.17,\n 8974: 22.264,\n 8975: 21.045,\n 8976: 19.897,\n 8977: 19.444,\n 8978: 19.639,\n 8979: 19.428,\n 8980: 20.256,\n 8981: 22.959,\n 8982: 25.389,\n 8983: 25.834,\n 8984: 25.498,\n 8985: 24.03,\n 8986: 22.577,\n 8987: 20.077,\n 8988: 19.866,\n 8989: 19.303,\n 8990: 19.139,\n 8991: 19.303,\n 8992: 20.944,\n 8993: 22.85,\n 8994: 24.452,\n 8995: 25.694,\n 8996: 25.444,\n 8997: 24.061,\n 8998: 22.897,\n 8999: 20.803,\n 9000: 19.381,\n 9001: 19.842,\n 9002: 18.912,\n 9003: 19.397,\n 9004: 19.725,\n 9005: 22.334,\n 9006: 24.538,\n 9007: 26.42,\n 9008: 25.569,\n 9009: 23.639,\n 9010: 22.116,\n 9011: 21.17,\n 9012: 20.155,\n 9013: 18.764,\n 9014: 19.592,\n 9015: 19.35,\n 9016: 21.256,\n 9017: 23.78,\n 9018: 24.436,\n 9019: 25.389,\n 9020: 25.561,\n 9021: 23.975,\n 9022: 22.538,\n 9023: 20.748,\n 9024: 19.397,\n 9025: 18.905,\n 9026: 19.584,\n 9027: 19.498,\n 9028: 20.709,\n 9029: 22.881,\n 9030: 25.334,\n 9031: 26.491,\n 9032: 26.225,\n 9033: 23.717,\n 9034: 22.514,\n 9035: 21.225,\n 9036: 19.967,\n 9037: 19.397,\n 9038: 19.397,\n 9039: 19.975,\n 9040: 20.686,\n 9041: 21.936,\n 9042: 24.655,\n 9043: 26.811,\n 9044: 25.889,\n 9045: 24.342,\n 9046: 22.538,\n 9047: 21.342,\n 9048: 20.944,\n 9049: 18.912,\n 9050: 18.866,\n 9051: 19.444,\n 9052: 21.866,\n 9053: 22.889,\n 9054: 24.975,\n 9055: 25.889,\n 9056: 25.694,\n 9057: 24.647,\n 9058: 22.491,\n 9059: 20.756,\n 9060: 18.569,\n 9061: 18.522,\n 9062: 18.998,\n 9063: 19.131,\n 9064: 20.319,\n 9065: 22.873,\n 9066: 24.186,\n 9067: 26.116,\n 9068: 26.295,\n 9069: 24.647,\n 9070: 23.139,\n 9071: 20.772}\n\n\nWe will now extract March to July data into separate series to be plotted:\n\nimport matplotlib.pyplot as plt\n \nxpoints = list(set(df['Year'].tolist()))\n \nfor ind,monthname in enumerate(months[2:6],3):\n    plt.plot(xpoints,df[df['Month']==ind]['Temp (C)'],label=monthname)\n     \nplt.show()"
  },
  {
    "objectID": "kleb-project/tools/third_party.html",
    "href": "kleb-project/tools/third_party.html",
    "title": "Third Party Tools",
    "section": "",
    "text": "Third Party Tools\nDescription: External tools or APIs that integrate with EGIS services (e.g., Tableau, Leaflet, QGIS).\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Tools",
      "Third Party Tools"
    ]
  },
  {
    "objectID": "kleb-project/tools/experience_builder.html",
    "href": "kleb-project/tools/experience_builder.html",
    "title": "Experience Builder",
    "section": "",
    "text": "Description: A web app builder allowing users to create custom layouts, workflows, and interactive GIS applications.\nExample Application 1: Water Portal * Water Portal - Overview\nExample Application 2: Landslide Viewer Experience * Landslide Viewer Experience - Overview\nExample Application 3: NISAR Mission Observation Plan * NISAR Mission Observation Plan - Overview\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Tools",
      "Experience Builder"
    ]
  },
  {
    "objectID": "kleb-project/tools/appbuilder.html",
    "href": "kleb-project/tools/appbuilder.html",
    "title": "Web AppBuilder",
    "section": "",
    "text": "Web App Builder Examples\nDescription: Legacy app creation tool offering widget-based web applications with configurable maps and tools.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Tools",
      "Web AppBuilder"
    ]
  },
  {
    "objectID": "kleb-project/services/ogc_services.html",
    "href": "kleb-project/services/ogc_services.html",
    "title": "OGC Services",
    "section": "",
    "text": "Description: OThe Open Geospatial Consortium (OGC) is an international voluntary consensus standards organization. The mission of the OGC is to develop, approve, and maintain standards for making maps and related geographic data available and shareable over the web. Using OGC services and encodings enables open access to geographic data and software functionality, allowing organizations to incorporate their GIS data and services into any app on a variety of computing and mobile devices. These open services and encodings help improve the sharing and interoperability of geospatial information.\n\nService Type Capabilities\n\n\n\n\n\n\n\n\n\nService Type\nFull Name\nPrimary Purpose\nOutput Format\nUse Case\n\n\n\n\nWMS\nWeb Map Service\nProvides dynamically rendered map images generated on the server from vector or raster data. Allows clients to request specific layers, apply styles, and control symbology, extent, and format on the fly. Map request are drawn in real time.\nRendered map images (PNG, JPEG, GIF, TIFF, BMP, SVG, SVG+xml, image/bil)\nFor live, styled maps that respond to layer visibility, symbology, or temporal filters (ex. viewing weather patterns, satellite mosaics, or real-time operational data). Ideal for interoperable map visualization across different GIS clients.\n\n\nWMTS\nWeb Map Tile Service\nProvides cached map tiles that conform to the WMS standard but are pre-rendered and stored in a tile cache. Optimized for performance, delivering tiles rapidly instead of drawing dynamically for each request; improves speed and scalability for high-demand basemap or imagery layers.\nPre-rendered image tiles (PNG, JPEG, GIF, TIFF, BMP)\nFor fast, scalable basemap delivery like large imagery or topographic maps where data doesn’t change frequently. Ideal for web map backdrops or mobile apps that require quick, seamless panning and zooming.\n\n\nWFS\nWeb Feature Service\nProvides access to the underlying vector features and attributes (not just images). Clients can query, filter, and retrieve the actual geometries and attribute data for analysis, editing, or integration; can enable both read and transactional operations depending on the configuration.\nFeature geometries and attributes (GML2, GML3, GeoJSON, KML, Shapefile, CSV, application/json, application/vnd.geo+json)\nFor data-level access for analysis or editing (ex. performing spatial queries, overlay analysis, or downloading vector datasets for modeling). Ideal for analytical workflows or apps that need interoperable, editable vector data.\n\n\n\n\nTechnical Capabilities\n\n\n\n\n\n\n\n\nCapability (Esri Context)\nWMS\nWMTS\nWFS\n\n\n\n\nOGC Specification Version\n1.0.0 – 1.3.0\n1.0.0\n1.0.0 – 2.0\n\n\nSupported Operations\nRequired for compliance: GetCapabilities, GetMap Optional: GetFeatureInfo, GetLegendGraphic, GetStyles, GetSchemaExtension\nRequired for compliance: GetCapabilities, GetTile Optional: GetFeatureInfo\nRequired for compliance: GetCapabilities, DescribeFeatureType, GetFeature Optional: Transaction, LockFeature , GetPropertyValue\n\n\nTime / Elevation Support\nSupports Time and Elevation parameters\nSupports Time and Elevation parameters IF cached as dimension\nSupports temporal and spatial filters",
    "crumbs": [
      "The KLEB project",
      "Services",
      "OGC Services"
    ]
  },
  {
    "objectID": "kleb-project/services/index.html",
    "href": "kleb-project/services/index.html",
    "title": "Services",
    "section": "",
    "text": "NASA’s Earthdata Geographic Information System (EGIS) is a set of cloud-native geospatial data services that make NASA Earth science data easier to discover, access, visualize, and analyze in common Geographic Information System (GIS) environments. These services provide GIS-ready imagery and raster/feature data that comply with standards like ArcGIS and Open Geospatial Consortium (OGC), so users can integrate NASA satellite and Earth observation data directly into tools such as ArcGIS, QGIS, and other GIS software.\n\nSee the following links for specific information:\n\nAnnouncements\nFeature Services\nImage Services\nMap Services\nOGC Services",
    "crumbs": [
      "The KLEB project",
      "Services"
    ]
  },
  {
    "objectID": "kleb-project/services/feature_services.html",
    "href": "kleb-project/services/feature_services.html",
    "title": "Feature Services",
    "section": "",
    "text": "Description: Feature services allow access to individual vector features and their attributes. Designed to be interactive, they support querying, editing, and syncing of geographic features and are commonly used in web maps and apps. Uses client-side rendering, meaning the feature geometries and attributes are downloaded to the client (e.g., web browser, ArcGIS Pro), and the client applies symbology locally. Best for editable, transactional, or analytical workflows. Preferred by Esri for Living Atlas Nominations.\n\nBasic Capabilities\n\n\n\n\n\n\nCapability\nFeature Service (Web Feature Layer)\n\n\n\n\nData Type\nVector and tables\n\n\nEditing Support\nYes\n\n\nRendering\nClient-side rendering (symbology configurable per client)\n\n\nPerformance\nOptimized for editing operations and small to medium datasets\n\n\nStorage\nHosted (copied) or references registered enterprise data\n\n\nCaching\nNo - renders on demand\n\n\nSymbolization\nStored with the layer and applied on the client; can be restyled interactively\n\n\nOGC Compliance\nSupports publishing as WFS (if data is copied)\n\n\nExport Options\nFull vector and table export supported; File Geodatabase (.gdb.zip), Shapefile (.zip), CSV (.csv), GeoJSON (.geojson), Feature Collection (.json), KML (.kmz), and Excel (.xlsx)\n\n\n\n\nTechnical Capabilities\n\n\n\n\n\n\nEnvironment\nFeature Service (Web Feature Layer)\n\n\n\n\nWeb Analysis Tools (ArcGIS Online / ArcGIS Enterprise Map Viewer)\nFully supported in standard web analysis tools (Buffer, Overlay Layers, Summarize Within, Dissolve Boundaries, Calculate Field, etc.). Users can run analysis directly in the browser since vector features are accessible.\n\n\nArcGIS Pro Geoprocessing Tools\nFully supported in most geoprocessing tools (Select by Location, Clip, Intersect, Spatial Join, etc.). ArcGIS Pro accesses features through REST and processes them as vector inputs.\n\n\nPython (ArcPy or ArcGIS API for Python)\nLFully compatible. The ArcGIS API for Python and ArcPy can query, filter, edit, and analyze features directly (FeatureLayer.query, SpatialDataFrame, etc. workflows).\n\n\nServer-side Analysis (Geoprocessing Services)\nFully supported - Can be used as both input and output in server-based geoprocessing models and analysis tools. Outputs can be written back to new hosted feature layers or tables.\n\n\nQuerying\nFully supported",
    "crumbs": [
      "The KLEB project",
      "Services",
      "Feature Services"
    ]
  },
  {
    "objectID": "kleb-project/resources/index.html",
    "href": "kleb-project/resources/index.html",
    "title": "Resources",
    "section": "",
    "text": "General Documentation Links\nDescription: Official links to resources, best practices, and product documentation.\nGIS at NASA: Landing page for information relating to NASA data and services. * Improving the Discovery, Access, and Use of Earth Science Data | NASA Earthdata\nEarthdata Tutorials: “How To” guides on integration and usage of NASA data. * Tutorials | NASA Earthdata\nTroubleshooting Guides: * Earthdata GIS Forum",
    "crumbs": [
      "The KLEB project",
      "Resources"
    ]
  },
  {
    "objectID": "kleb-project/resources/external_resources.html",
    "href": "kleb-project/resources/external_resources.html",
    "title": "External Resources",
    "section": "",
    "text": "Description: Useful third-party resources, such as WMS validators, OGC standards, or open GIS datasets. GitHub, Stacked Overflow, etc. Shape\nMap services/layers  Feature Service/layers \nEarthdata GIS Pathfinder\nGetting Started:\n\nImage Services Wiki\nImage Services StoryMap\n\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Resources",
      "External Resources"
    ]
  },
  {
    "objectID": "kleb-project/egis-limitations/service_capability.html",
    "href": "kleb-project/egis-limitations/service_capability.html",
    "title": "Service Capabilites",
    "section": "",
    "text": "Image Service Capability Index\n\n\nDescription: Scores are based on a subset of NASA Earthdata image services (n=21) that were fully or partially compliant in compatibility areas. Sources include EGIS and non-EGIS image services. Out Of The Box is abridged to OOTB.\n\nArcGIS ImageServer Connector Plugin in QGIS\nWhile the ArcGIS ImageServer Connector plugin is also available and provides additional functionality with EGIS Image Services, the plugin was built by the Swedish Agency for Marine and Water Management and is no longer actively supported. The last update was in August 2019.\n\n\nTemporal Capabilities in QGIS\nEGIS image services generally do not show temporal slices, even with troubleshooting, no matter which importa methodology used (ArcGIS REST, WMS/WMTS, or plugins). Dynamic temporal control or using the temporal controller do not yield intended results. Some service WMS capabilities may provide workarounds while enhancements are underway.\n\n\nRaster Processing in QGIS\nIf using the ArcGIS REST Connection import method, most geoprocessing tools fail as the functions are not built to handle services and are therefore looking for a local file to run the analytics on.\nRaster processing was successful when using the ImageServer Connector plugin Import method.\n\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "EGIS Limitations",
      "Service Capabilites"
    ]
  },
  {
    "objectID": "kleb-project/egis-limitations/index.html",
    "href": "kleb-project/egis-limitations/index.html",
    "title": "EGIS Limitations",
    "section": "",
    "text": "EGIS Limitations\nEGIS is currently providing free and open access to our publicly available content; no accounts are required. Sign-in options to EGIS are limited to internal NASA use only and are not available for general use. This limitation will also prevent users from saving or printing web maps, however the services can be used in other clients, tools, and web mapping platforms.\n\nSee the following links for specific information:\n\nActive Development\nAuthentication\nDownload Limitations\nService Capabilities",
    "crumbs": [
      "The KLEB project",
      "EGIS Limitations"
    ]
  },
  {
    "objectID": "kleb-project/egis-limitations/active_dev.html",
    "href": "kleb-project/egis-limitations/active_dev.html",
    "title": "Active Development",
    "section": "",
    "text": "Description: EGIS is regularly onboarding collections and publishing new services, please visit the NASA Catalog or NASA Portal to see the full list of publicly available content. NASA’s Earth observations include ~50,000 collections of over 100 petabytes of data, it is important to note that EGIS does not currently provide geospatial services for the complete repository.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "EGIS Limitations",
      "Active Development"
    ]
  },
  {
    "objectID": "kleb-project/behaviors/versioning.html",
    "href": "kleb-project/behaviors/versioning.html",
    "title": "Versioning",
    "section": "",
    "text": "Version specific behavior\nDescription: Behavior changes, bugs, or enhancements tied to specific versions of Esri software (e.g., ArcGIS Enterprise 11.2 vs. 11.1 or ArcGIS Pro 3.3 vs 3.5.4).\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Product and Platform Behavior",
      "Versioning"
    ]
  },
  {
    "objectID": "kleb-project/behaviors/index.html",
    "href": "kleb-project/behaviors/index.html",
    "title": "Product and Platform Behavior",
    "section": "",
    "text": "Product and Platform Behavior\nThe NASA Earthdata Geographic Information System (EGIS) Data Services platform is expected to provide reliable, standardized, and user-friendly access to NASA Earth science data within common GIS environments. The platform should deliver GIS-ready datasets that integrate seamlessly with tools such as ArcGIS and QGIS, minimizing the need for manual data processing or format conversion. It is expected to support open standards, including OGC services, to ensure interoperability across applications and workflows. The platform should enable efficient data discovery, visualization, and analysis through cloud-based services, allowing users to access large datasets without downloading them locally. Consistent performance, accurate metadata, and timely updates are essential to support scientific research, decision-making, and operational use.\n\nSee the following links for specific information:\n\nEndpoints\nPop Up Behavior\nKnown Software Version Behavior\nWeb vs Desktop Behavior",
    "crumbs": [
      "The KLEB project",
      "Product and Platform Behavior"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EGIS Service Information, Tools, and Resources",
    "section": "",
    "text": "These docs help you use the services provided by the Earthdata Search Platform and NASA’s CMR STAC. Its purpose is to be a resource for interacting with NASA data and provide use cases as well as behaviors in ArcGIS Pro and open-source data.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "EGIS Service Information, Tools, and Resources",
    "section": "",
    "text": "These docs help you use the services provided by the Earthdata Search Platform and NASA’s CMR STAC. Its purpose is to be a resource for interacting with NASA data and provide use cases as well as behaviors in ArcGIS Pro and open-source data.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#kleb",
    "href": "index.html#kleb",
    "title": "EGIS Service Information, Tools, and Resources",
    "section": "Known Limitations and Expected Behaviors",
    "text": "Known Limitations and Expected Behaviors\n\n\n\n\nOverview and Guidance\n\nPurpose of the Documentation Hub\n\n\n\n\n\nEGIS Limitations\n\nNo Download\nActive Development\nAuthentication\nImage Service Capability Index\n\n\n\n\n\nServices\n\nMap Services\nFeature Services\nImage Services\nOGC Services\nService Announcements\n\n\n\n\n\nProduct and Platform Behavior\n\nWeb vs Desktop\nPop-Ups\nVersion-Specific Behavior\nOGC vs COTS Endpoints\n\n\n\n\n\n\n\n\n\nApplication Integrations & Tools\n\nDashboards\nExperience Builder\nWeb AppBuilder\nThird Party Tools\n\n\n\n\n\nData Standards & Managements\n\nData Standards & Managements\n\n\n\n\n\nResources\n\nGeneral Documentation Links\nHow-To\nExternal Resources",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#tutorials",
    "href": "index.html#tutorials",
    "title": "EGIS Service Information, Tools, and Resources",
    "section": "Tutorials",
    "text": "Tutorials\nTo learn from examples, see the Tutorial Page for  examples of data services and images.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#egis-content-release-tracker",
    "href": "index.html#egis-content-release-tracker",
    "title": "EGIS Service Information, Tools, and Resources",
    "section": "EGIS Content Release Tracker",
    "text": "EGIS Content Release Tracker\n\n\n\n\n\n\n\n\n\nRelease\nSummary\nDate\nOwner\n\n\n\n\n1.0\nInitial webpage build and population of existing content\n12/12/2025\nryan-barnhart",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "kleb-project/behaviors/endpoints.html",
    "href": "kleb-project/behaviors/endpoints.html",
    "title": "API Endpoints",
    "section": "",
    "text": "To use EGIS content outside of the web map viewer, access the “URL” at the bottom right of the content item page. This is the REST endpoint from which you can view or copy the URL to then bring into your tool, application, or client of choice.\n\n\n\nDirect Endpoint Example",
    "crumbs": [
      "The KLEB project",
      "Product and Platform Behavior",
      "API Endpoints"
    ]
  },
  {
    "objectID": "kleb-project/behaviors/endpoints.html#ogc-vs-cots-endpoints",
    "href": "kleb-project/behaviors/endpoints.html#ogc-vs-cots-endpoints",
    "title": "API Endpoints",
    "section": "OGC vs COTS Endpoints",
    "text": "OGC vs COTS Endpoints\n\nWMS\nDescription: Parameters passed in the URL of a WMS request to specify layers, coordinate systems, bounding boxes, image format, etc. (e.g., LAYERS=, SRS=, BBOX=).\n\n\nREST\nDescription: Parameters passed in the URL that represents a resource or functionality in a RESTful API. It acts as the interface where clients send requests to interact with the server. REST endpoints are integral to enabling communication between clients (e.g., web or mobile applications) and servers in a RESTful architecture.\n\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Product and Platform Behavior",
      "API Endpoints"
    ]
  },
  {
    "objectID": "kleb-project/behaviors/pop_up.html",
    "href": "kleb-project/behaviors/pop_up.html",
    "title": "Pop Up Behavior",
    "section": "",
    "text": "Pop Up Behavior\nDescription: Interactive UI elements that display attribute data when a user clicks a feature. Behavior and formatting differ across platforms.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Product and Platform Behavior",
      "Pop Up Behavior"
    ]
  },
  {
    "objectID": "kleb-project/behaviors/web_vs_desktop.html",
    "href": "kleb-project/behaviors/web_vs_desktop.html",
    "title": "Development",
    "section": "",
    "text": "Web vs Desktop Development\nDescription: Differences in service behavior, UI rendering, interactivity, and limitations between web applications (e.g., ArcGIS Online, Experience Builder) and desktop clients (e.g., ArcGIS Pro).\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Product and Platform Behavior",
      "Development"
    ]
  },
  {
    "objectID": "kleb-project/egis-limitations/authentication.html",
    "href": "kleb-project/egis-limitations/authentication.html",
    "title": "Authentication",
    "section": "",
    "text": "EGIS is currently providing free and open access to our publicly available content; no accounts are required. Sign-in options to EGIS are limited to internal NASA use only and are not available for general use. This limitation will also prevent users from saving or printing web maps, however the services can be used in other clients, tools, and web mapping platforms.\nServices are free to access using ArcGIS Pro, Open Source Software (such as QGIS), or via NASA provided APIs. In order to use or download data users need to create a free account at NASA Catalog by clicking Log In.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "EGIS Limitations",
      "Authentication"
    ]
  },
  {
    "objectID": "kleb-project/egis-limitations/no_download.html",
    "href": "kleb-project/egis-limitations/no_download.html",
    "title": "No Download",
    "section": "",
    "text": "Description: At this time, EGIS services do NOT offer users the ability to download raw data. The ArcGIS Image Services provide Analysis-Ready-Data as a service, allowing users to perform functions and analytics to the underlying data without requiring the download of files. To access to the full NASA Earth observation repository for data download, please visit Earthdata Search.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "EGIS Limitations",
      "No Download"
    ]
  },
  {
    "objectID": "kleb-project/index.html",
    "href": "kleb-project/index.html",
    "title": "The KLEB project",
    "section": "",
    "text": "The Known Limitations and Expected Behaviors project is focused on providing users with a clear, transparent understanding of the constraints, performance characteristics, and expected behaviors of the data and data services provided by NASA EGIS.",
    "crumbs": [
      "The KLEB project"
    ]
  },
  {
    "objectID": "kleb-project/index.html#project-context",
    "href": "kleb-project/index.html#project-context",
    "title": "The KLEB project",
    "section": "",
    "text": "The Known Limitations and Expected Behaviors project is focused on providing users with a clear, transparent understanding of the constraints, performance characteristics, and expected behaviors of the data and data services provided by NASA EGIS.",
    "crumbs": [
      "The KLEB project"
    ]
  },
  {
    "objectID": "kleb-project/index.html#project-goals",
    "href": "kleb-project/index.html#project-goals",
    "title": "The KLEB project",
    "section": "Project Goals",
    "text": "Project Goals\n\nUnderstand Service Constraints: Clearly communicate the limitations, such as data access rates, storage capacity, response time, geographical coverage, and temporal availability, so users can make informed decisions about how to effectively use the data services.\nSet User Expectations: Outline the expected behaviors and performance standards (e.g., data refresh rates, accuracy, and latency), ensuring users know what to expect in terms of data quality and service reliability.\nAssist in Problem Diagnosis: Provide insights into common issues that might arise (e.g., service outages, data inconsistencies, or connection errors) and offer troubleshooting tips or solutions to help users mitigate disruptions.\nImprove User Experience: Guide users in optimizing their use of data services by offering best practices and workarounds for known limitations, helping them avoid frustration or misinterpretation of data.\nPromote Transparency: Providing detailed documentation about the potential issues or areas where the service may not meet specific user needs, whether due to data accessibility, scalability, or other factors.\nFacilitate Integration: Help developers and users integrate the service more effectively by outlining technical behaviors (e.g., API limitations, expected input/output formats, or rate limits), ensuring seamless data consumption and interaction.\n\n\nStakeholder Benefits\n\nGeneral Public: Interactive stories and test cases\nData producers/Researchers (Curators): processing and self-publishing\nCommunication: Update user community via https://eosdis-nasa.github.io/earthdata-gis/ homepage regarding new content or features added.",
    "crumbs": [
      "The KLEB project"
    ]
  },
  {
    "objectID": "kleb-project/resources/how_to.html",
    "href": "kleb-project/resources/how_to.html",
    "title": "How To",
    "section": "",
    "text": "Instructional Links and Documentation\nDescription: Short instructional videos or documentation covering specific workflows or tools.\n\nNASA EOSDIS Tutorials Github\nEarthdata Tutorials (future: filter or query EGIS or GIS specifically)\n\nEarthdata GIS Resouces YouTube: Video based tutorials and demo utilizing NASA content * Earthdata GIS Resources - YouTube\n\n\nAccess Earthdata Content In ArcGIS Pro\nFrom the NASA Earthdata GIS collection Map click “Open via Pro” to initiate an item download. When you attempt to open the downloaded item (.pitemx) in ArcGIS Pro you will most likely receive an error. This is a known bug with a workaround.\nSpecifically, errors occur when you try to open an item from Portal A while logged into Portal B in ArcGIS Pro.\nAs a workaround, switch the active portal to the content’s home (Portal A). You do not need to have an EGIS Portal account or sign in to set your active portal to EGIS. Open the .pitemx file again.\nPortal URL for EGIS Items: NASA Portal\nHow to Switch Your Active Portal:\nClick the Sign In menu in the upper corner of ArcGIS Pro Click Manage Portals If the EGIS Portal is Not Registered: Click Add Portal Enter the EGIS Portal URL Save Registration If the EGIS Portal is Already Registered: Click Switch to designate as Active Portal\n\n\n\nChanging Portal to add .pitemx\n\n\n\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Resources",
      "How To"
    ]
  },
  {
    "objectID": "kleb-project/services/announcements.html",
    "href": "kleb-project/services/announcements.html",
    "title": "Announcements",
    "section": "",
    "text": "Description: Time-sensitive updates on service deployments, maintenance windows, changes in availability, or planned deprecations.",
    "crumbs": [
      "The KLEB project",
      "Services",
      "Announcements"
    ]
  },
  {
    "objectID": "kleb-project/services/image_services.html",
    "href": "kleb-project/services/image_services.html",
    "title": "Image Services",
    "section": "",
    "text": "Description: Designed for visualization, access, and analysis of raster and imagery data such as satellite, aerial, and elevation datasets. Imagery services can draw dynamically from source data or from cached tiles for faster performance. They support raster functions, multidimensional data, mensuration, and metadata access. Best suited for analytical, visualization, and sharing workflows that require access to pixel values and raster attributes\n\nCapabilities\n\n\n\n\n\n\nCapability\nDescription\n\n\n\n\nData Type\nRaster datasets, image collections, mosaic datasets, multidimensional imagery, and elevation models.\n\n\nEditing Support\nPixel values cannot be edited directly; modifying imagery requires updating source data and republishing. Editing supports modifying service properties such as symbology, rendering rules, raster functions, and display or performance settings.\n\n\nRendering\nCan draw dynamically from data (server-side rendering) or use cached tiles.\n\n\nPerformance Optimization\nSupports browser and server-side caching, compression, and selective cache building to improve rendering performance and reduce bandwidth usage\n\n\nStorage\nCan be referenced from enterprise/data stores or copied and hosted to ArcGIS Online. Hosted imagery services are stored in ArcGIS Online’s Cloud Raster Format (CRF).\n\n\nCaching\nOptional. Supports dynamic draw, cached draw/pre-rendered tiles, new or existing caches, and multiple tiling schemes. Supports export of cache tiles for offline use.\n\n\nCompression (how pixels are stored and transmitted)\nSupports JPEG, LERC, LZ77, or none.\n\n\nSymbolization\nDefined by processing templates, default stretches, and resampling methods\n\n\nOGC Compliance\nSupports WMS (1.0–1.3) capabilities for interoperability with external GIS clients (ex. QGIS). Public sharing is required for OGC layers to function correctly.\n\n\nMensuration Tools (making geometric measurements directly from imagery)\nSupports distance, area, height, and shadow measurements depending on available source data and sensor metadata.\n\n\n\n\nTechnical Capabilities\n\n\n\n\n\n\nEnvironment\nDescription\n\n\n\n\nArcGIS Pro\nFully supported for authoring, visualization, and analysis. Users can configure rendering, compression, resampling, orthorectification, and processing templates, and can publish or overwrite imagery layers.\n\n\nWeb Map Viewers (ArcGIS Online / Enterprise)\nSupports basic interactive access to imagery services for visualization, filtering, and raster analysis. Users can apply raster functions, adjust rendering, and explore time or multidimensional data, but cannot author or publish imagery services.\n\n\nRaster Functions and Processing\nApplies raster functions and templates for on-the-fly analysis and visualization, such as NDVI, hillshade, pan-sharpening, terrain analysis, or time-slice extraction from multidimensional data. Hosted tiled layers process imagery on the client; dynamic layers process imagery on the server.\n\n\nAnalysis Tools\nSupports raster analysis tools such as Clip, Zonal Statistics, Slope, Aspect, etc. when raster analysis privileges are enabled.\n\n\nPython (ArcPy / ArcGIS API for Python)\nFully compatible for publishing, querying pixel values, managing caches, and performing image analysis using arcgis.raster modules or ArcPy raster functions.\n\n\nServer-side Analysis (Geoprocessing Services)\nFully supported when published to ArcGIS Image Server. Enables custom geoprocessing models or Python script tools to run server-side, using imagery layers as inputs and outputs for batch or scheduled processing.\n\n\nExport Options\nSupports exporting to TIFF, JPEG, PNG, or other raster formats through REST endpoints. Clients may download cache tiles if enabled.",
    "crumbs": [
      "The KLEB project",
      "Services",
      "Image Services"
    ]
  },
  {
    "objectID": "kleb-project/services/map_services.html",
    "href": "kleb-project/services/map_services.html",
    "title": "Map Services",
    "section": "",
    "text": "Description: Designed for fast map visualization and rendering of layers, including both vector and raster data. Uses server-side rendering, meaning the server draws the map and sends pre-rendered images (map tiles or dynamic map images) to the client, which displays them without local restyling. Supports querying and visualization, but not editing. Can be dynamic (drawn on-the-fly) or cached (tiled) for high performance. Ideal for large-scale visualization, analysis layers, and read-only data delivery.\n\nBasic Capabilities\n\n\n\n\n\n\nCapability\nMap Service (Image Layer)\n\n\n\n\nData Type\nVector, raster sublayers, and tables\n\n\nEditing Support\nNo - read-only (can optionally include a dependent feature layer for editing)\n\n\nRendering\nServer-side rendering (authoritative symbology defined at publish)\n\n\nPerformance\nOptimized for visualization of large datasets (dynamic draw or cached tiles)\n\n\nStorage\nReferences registered data (Enterprise) or caches data to server\n\n\nCaching\nYes - Can use new or existing tile caches for faster rendering\n\n\nSymbolization\nAuthored in ArcGIS Pro and rendered server-side; fixed symbology unless dynamic workspaces are enabled\n\n\nOGC Compliance\nSupports publishing as WMS, WFS, WCS, OGC API (Features, and KML)\n\n\nExport Options\nMap image export (PNG, JPEG, PDF); limited vector exports for queries\n\n\n\n\nTechnical Capabilities\n\n\n\n\n\n\nEnvironment\nMap Service (Image Layer)\n\n\n\n\nWeb Analysis Tools (ArcGIS Online / ArcGIS Enterprise Map Viewer)\nLimited - Map image layers cannot be used directly in web analysis tools because they serve images, not features. Only the associated feature layer (if one exists) can be used in these tools.\n\n\nArcGIS Pro Geoprocessing Tools\nLimited - Only sublayers that expose query operations can be used as read-only inputs. Dynamic map layers (images) cannot serve as direct inputs for vector analysis tools.\n\n\nPython (ArcPy or ArcGIS API for Python)\nLimited. ArcPy and the ArcGIS API can only perform REST queries on sublayers with query enabled. Map image rendering (PNG/JPEG) cannot be processed in analytical workflows unless converted.\n\n\nServer-side Analysis (Geoprocessing Services)\nLimited - Can be used as input only if the service supports query operations. Outputs cannot overwrite or update a map image layer. Often used together with an associated feature layer for data-driven geoprocessing services.\n\n\nQuerying\nLimited - does not include editing and attachments",
    "crumbs": [
      "The KLEB project",
      "Services",
      "Map Services"
    ]
  },
  {
    "objectID": "kleb-project/standards/index.html",
    "href": "kleb-project/standards/index.html",
    "title": "Standards",
    "section": "",
    "text": "Data Standards and Management\nDescription: Required metadata elements for datasets and services, such as title, description, spatial extent, and update frequency.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Standards"
    ]
  },
  {
    "objectID": "kleb-project/tools/dashboards.html",
    "href": "kleb-project/tools/dashboards.html",
    "title": "Dashboards",
    "section": "",
    "text": "Description: Web apps designed for visualizing real-time or aggregated spatial data using charts, indicators, and maps.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "The KLEB project",
      "Tools",
      "Dashboards"
    ]
  },
  {
    "objectID": "kleb-project/tools/index.html",
    "href": "kleb-project/tools/index.html",
    "title": "Tools",
    "section": "",
    "text": "Application Integration and Tools\nNASA’s EGIS teams focus on enabling seamless connectivity between systems and providing users with practical capabilities to access, process, and use data efficiently. This includes support for standard APIs, data services, and interoperability frameworks that allow applications to integrate with external platforms and workflows. Integration tools are expected to work across environments, reducing the need for custom development and manual data handling.\n\nSee the following links for specific information:\n\nWeb AppBuilder\nDashboards\nExperience Builder\nThird Party Tools",
    "crumbs": [
      "The KLEB project",
      "Tools"
    ]
  },
  {
    "objectID": "kleb-project/tracker/index.html",
    "href": "kleb-project/tracker/index.html",
    "title": "Resource Tracker",
    "section": "",
    "text": "Resource Tracker and Information\nDescription: The intent of the resource tracker is to improve efficiency, accountability, and decision-making by ensuring data and content is visible, well-documented, and easier to manage and integrate into workflows.\n\nThis page is under development. Please check back for updates.",
    "crumbs": [
      "Release Tracker"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "EGIS Tutorials",
    "section": "",
    "text": "Tutorials\n\nGetting Started with ArcGIS\nTempo Image Service with BBOX\nTempo Image Service with XY Points",
    "crumbs": [
      "EGIS Tutorials"
    ]
  },
  {
    "objectID": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_XYPoint.html",
    "href": "tutorials/TEMPO_Image_Service_Programmatic_Access_Example_XYPoint.html",
    "title": "Accessing, Analyzing, & Visualizing TEMPO data through ArcGIS Image Services Programmatically",
    "section": "",
    "text": "Overview Selected TEMPO data have been processed into free, publicly available ArcGIS image services that provide pre-filtered, analysis-ready imagery/data.\nThis notebook illustrates the following:\n\nChoose a TEMPO image service to query\nSelect time period and point (X,Y) of interest\nView data values for point of interest in a table\nChart returned values for point of interest\nView imagery for the time period of interest in interactive mapper\n\nWhy ArcGIS image services? Each TEMPO ArcGIS image service is hosted at a service URL, which has several built-in functions provided through the ArcGIS image service REST API. These functionalities can be accessed via webpage interfaces or called programatically, providing ways to access, analyze, and display the TEMPO data.\n\nPrerequisites\nNote: ESRI software/licenses are NOT required to access the services via the interfaces or programatically. No GIS software is required to access these TEMPO image services (although there are many methods to use these services in GIS).\nRequired: - Basic Python knowledge (variables, loops, functions) - Familiarity with TEMPO instrument and data products\nPython Libraries: - matplotlib - for creating plots and visualizations - numpy - for numerical operations - ipyleaflet - for visualization in interactive mapper - requests - for sending HTTP requests to service API\n\n\nData & Scope\nEach TEMPO ArcGIS image service has a portal page with detailed descriptions on the service, the filtering applied, geographic and temporal coverage, as well as access to the online map viewer to view the image service. It is strongly recommended to read over the service description to ensure understanding of the data.\nThe TEMPO image services are available in the Esri Living Atlas of the World.\nThe example in this notebook uses: - Product: TEMPO_NO2_L3_V04 (Level-3 gridded NO₂ tropopsheric column) - Resolution: approximately 2.1 km × 4.4 km, hourly during daylight - Coverage: North America - Example region: Colorado, United States\nMethods apply to other TEMPO products (formaldehyde, ozone, etc.) and regions within North America.\nTEMPO Version 04 (V04) data are available from September 17, 2025 to present. The previous TEMPO data version (V03) was released publicly on May 24, 2024, and cover the time period from August 2, 2023 to September 16, 2025. All observations since the beginning of the mission are being reprocessed with V04 algorithms, with V04 products becoming publicly available in this service as they are reprocessed. Once the V03 data reprocessing is completed, the V03 service will be deprecated.\n\n\nNotebook Author / Affiliation\n\nAuthor: Atmospheric Science Data Center\nQuestions? Please post questions on the NASA Earthdata Forum\n\n\n\n1. Setup\n\n1.1 Install Python packages\n\n#Install Python packages if not available\n#!pip install --quiet ipywidgets nodejs traitlets numpy pandas matplotlib\n\n\n\n1.2 Import Python libraries\n\n#For accessing data and creating chart\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport datetime as dt\nfrom dateutil.relativedelta import relativedelta\nimport time\nfrom datetime import datetime, timezone\n\n#For creating interactive mapper\nfrom ipyleaflet import Map, ImageService, basemaps,  WidgetControl\nfrom ipywidgets import SelectionSlider, Layout, Label, VBox\nfrom datetime import datetime, timezone\nfrom ipywidgets import Output, HTML\n\n#Set dataframe view options to ensure all rows appear (optional)\npd.set_option('display.max_rows', None)\n\n\n\n1.3 Enable function to convert between human-readable dates and Unix timestamps\nThe TEMPO image services store the timestamp of each data scan as a Unix timestamp (e.g., 1752582321), which is the number of seconds since January 1, 1970 UTC. As these integers are not intuitive, we will use two custom functions to convert between Unix timestamps and human-readable date time strings.\n\n#function to take input time as string and convert to integer of seconds since unix epoch UTC (Jan 1, 1970)\ndef convert_to_milliseconds(date_time_str):\n    \"\"\"Converts a date-time string in 'YYYY-MM-DD HH:MM:SS' format to milliseconds since epoch.\"\"\"\n    inputDate = dt.datetime.strptime(date_time_str, \"%Y-%m-%d %H:%M:%S\")\n    return int(inputDate.replace(tzinfo=timezone.utc).timestamp() * 1000)\n\n#function to take input time as integer of seconds since unix epoch UTC (Jan 1, 1970) and convert to string in 'YYYY-MM-DDTHH:MM:SSZ' format\ndef convert_from_milliseconds(milliseconds_since_epoch):\n    \"\"\"Converts milliseconds since epoch to a date-time string in 'YYYY-MM-DDTHH:MM:SSZ' format.\"\"\"\n    inputDateMilli = datetime.fromtimestamp((milliseconds_since_epoch)/ 1000, tz=timezone.utc)\n    return inputDateMilli.strftime('%Y-%m-%dT%H:%M:%SZ')\n\n\n\n\n2. User selections\nUsers can select variable, time, and point (X,Y) of interest or use default options. Several of the following sections allow users to choose between various options to tailor this code to their desired analysis. These sections have a default option that will be used if no changes are made. To select one of the other available options, users must adjust which lines of code are commented out (the # at the beginning of the code line) as noted in the instructions for the section.\n\n2.1 Choose TEMPO product/variable of interest\nThe default is TEMPO NO2 tropospheric column. Users may instead select formaldehyde (HCHO) total column or total column ozone (only one service/variable can be selected at a time).\n\n# Select service URL and variable\n'''Note: Only one image_service_url and corresponding variable_name can be used at a time. The other options should be commented out.'''\n\n# Option 1: NO2 Image Service (V04 data; data range: September 17, 2025 - present) (deafault variable)\nimage_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C3685896708-LARC_CLOUD/TEMPO_NO2_L3_V04_HOURLY_TROPOSPHERIC_VERTICAL_COLUMN/ImageServer\"\nvariable_name = \"NO2_Troposphere\"\n\n# Option 2: Formaldehyde Image Service v4\n#image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C3685897141-LARC_CLOUD/TEMPO_HCHO_L3_V04_HOURLY_VERTICAL_COLUMN/ImageServer\"\n#variable_name = \"HCHO\"\n\n# Option 3: Ozone Image Service v4\n# image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C3685896625-LARC_CLOUD/TEMPO_O3TOT_L3_V04_HOURLY_OZONE_COLUMN_AMOUNT/ImageServer\"\n# variable_name = \"Ozone_Column_Amount\"\n\n#Option 4: NO2 image service (V03 data; data range: August 2, 2023 - September 16, 2025)\n#image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C2930763263-LARC_CLOUD/TEMPO_NO2_L3_V03_HOURLY_TROPOSPHERIC_VERTICAL_COLUMN/ImageServer\"\n#variable_name = \"NO2_Troposphere\"\n\n#Option 5: Formaldehyde image service (V03 data; data range: August 2, 2023 - September 16, 2025)\n#image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C2930761273-LARC_CLOUD/TEMPO_HCHO_L3_V03_HOURLY_VERTICAL_COLUMN/ImageServer\"\n#variable_name = \"HCHO\"\n\n#Option 6: Ozone image service (V03 data; data range: August 2, 2023 - September 16, 2025)\n#image_service_url = \"https://gis.earthdata.nasa.gov/image/rest/services/C2930764281-LARC_CLOUD/TEMPO_O3TOT_L3_V03_HOURLY_OZONE_COLUMN_AMOUNT/ImageServer\"\n#variable_name = \"Ozone_Column_Amount\"\n\n\n\n2.2 Choose time period of interest\nThere are two options: * Option 1 (default): Time period is yesterday (last 24 hours from present) * Option 2: Manually select any time period within scope of TEMPO mission (August 2, 2023 - present)\nNote: User must comment out the option that is not in use. By default, Option 2 is commented out.\n\n# Choose starting and ending dates to run against\n\nyesterday = dt.datetime.today() - dt.timedelta(days=1)\ntoday = dt.datetime.today()\n\n#Option 1 (Default): Yesterday - today NOTE: converts local computer time to UTC\n'''Note: If using Option 2, comment out the two lines below:'''\nstart_date_time_str = str(dt.datetime(yesterday.year,yesterday.month,yesterday.day))\nend_date_time_str = str(dt.datetime(today.year,today.month,today.day, today.hour))\n\n#OR\n\n#Option 2: Select specifc time period of interest'''\n'''Note: If using Option 1, comment out the two lines below:'''\n#start_date_time_str = \"2025-05-06 0:01:00\" #in 'YYYY-MM-DD HH:MM:SS' format \"2025-04-20 12:00:00\"\n#end_date_time_str = \"2025-05-08 05:00:00\" #in 'YYYY-MM-DD HH:MM:SS' format \"2025-05-25 12:00:00\"\n\n# Convert user input dates to milliseconds since epoch\nstart_time = convert_to_milliseconds(start_date_time_str)\nend_time = convert_to_milliseconds(end_date_time_str)\n\nprint(f\"The time period of interest has been defined as: Start = {start_date_time_str} ({start_time}); End: = {end_date_time_str} ({end_time})\")\n\nThe time period of interest has been defined as: Start = 2025-10-06 00:00:00 (1759708800000); End: = 2025-10-07 13:00:00 (1759842000000)\n\n\n\n\n2.3 Choose point of interest\nUser may select one coordinate pair (X,Y) as a point of interest. Data values for this point will be returned when the image service is queried. (X = longitude, Y = latitude)\n\n#User chooses X,Y point of interest\n'''Note: Replace coordinate with desired point.\nCoordinate pair should be within quotation marks and have a comma between longitude and latitude values. Ex: \"-84,37\"\nThis variable is for the parameter \"geometry\" in the the URL service call below.'''\ncoor_pts = \"-104.676, 39.856\" # Denver Airport\n\n\n\n\n3. Identify number and timestamp of TEMPO scans in time period of interest\nThe timestamp of each TEMPO scan is stored as a dimension in the image service and can be accessed by sending a Multidimensional Info request to the service URL.\n\n#Create url for multidimensional info request\ndim_info_url = f\"{image_service_url}/multidimensionalInfo\"\n\n# Make request to service API\ndim_info = requests.get(dim_info_url, params={\"f\": \"json\"}).json()\nall_times = dim_info[\"multidimensionalInfo\"][\"variables\"][0][\"dimensions\"][0][\"values\"]\n\n# Filter to timestamps within the desired range and print count of scans found\ntimestamps = [t for t in all_times if start_time &lt;= t &lt;= end_time]\nprint(\"Number of TEMPO scans:\", len(timestamps))\n\n# Iterate through TEMPO scans and print timestamps as Unix epoch and date string\nfor t in timestamps:\n    date_strings = convert_from_milliseconds(t)\n    print(t, \" \", date_strings)\n\nNumber of TEMPO scans: 15\n1759752611000   2025-10-06T12:10:11Z\n1759755019000   2025-10-06T12:50:19Z\n1759757427000   2025-10-06T13:30:27Z\n1759761027000   2025-10-06T14:30:27Z\n1759764627000   2025-10-06T15:30:27Z\n1759768227000   2025-10-06T16:30:27Z\n1759771827000   2025-10-06T17:30:27Z\n1759775427000   2025-10-06T18:30:27Z\n1759779027000   2025-10-06T19:30:27Z\n1759782627000   2025-10-06T20:30:27Z\n1759783827000   2025-10-06T20:50:27Z\n1759785027000   2025-10-06T21:10:27Z\n1759786227000   2025-10-06T21:30:27Z\n1759789827000   2025-10-06T22:30:27Z\n1759792235000   2025-10-06T23:10:35Z\n\n\n\n\n4. Retreive data values for point of interest for selected time period\nData values for a selected X,Y point can be accessed by sending a Get Samples request to the service URL and returned in a json. The data are iterated through and values added to a dataframe. The dataframe is then viewed as a table.\n\n4.1 Get Samples request\nThe user provided information above (variable, time, X,Y point) are used to create a Get Samples request, which is sent to the service API. The data response is then stored in a json to access.\n\n# Create URL for Get Samples request\nbase_url = image_service_url+\"/getSamples/\"\nparams = {\n    \"geometry\": coor_pts, #Parameter that uses user's chosen lat/lon point\n    \"geometryType\": \"esriGeometryPoint\",\n    \"sampleDistance\": \"\",\n    \"sampleCount\": \"\",\n    \"mosaicRule\": f'{{\"multidimensionalDefinition\":[{{\"variableName\":\"{variable_name}\"}}]}}', #Parameter that uses user's chosen service variable\n    \"pixelSize\": \"\",\n    \"returnFirstValueOnly\": \"false\",\n    \"interpolation\": \"RSP_BilinearInterpolation\",\n    \"outFields\": \"\",\n    \"sliceId\": \"\",\n    \"time\": f\"{start_time},{end_time}\", #Parameter that uses user's chosen time period\n    \"f\": \"pjson\"\n}\n\n# Make the request to the service API\nresponse = requests.get(base_url, params=params)\ndata = response.json()\n\n\n\n4.2 Extract data into a dataframe\nThe returned json contains the variable, timestamps, and data values for the TEMPO scans in the selected time period. Not all scans in the selected time period may have data for the selected X,Y point. The retrieved data are iterated through to find which scans had data for the selected X,Y point and adding those data values with their corresponding timestamps to a dataframe. The dataframe is displayed in a table format.\n\n# Extract relevant information into a DataFrame\nsamples = []\nfor sample in data.get(\"samples\", []):\n    attributes = sample.get(\"attributes\", {})\n    var_value = attributes.get(variable_name)\n    # Only include the sample if it has a valid value for the variable of interest\n    '''Note: this will result in timeslices being excluded if there are no data for the point of interest.\n    Code may be modified to see all timestamps (i.e., include TEMPO scans where there are no data).'''\n    if var_value:\n        samples.append({\n            \"StdTime\": attributes[\"StdTime\"],\n            variable_name: float(var_value)  # Convert to float\n        })\n\n# Convert the list to a DataFrame\ndf = pd.DataFrame(samples)\n\n# Check if dataframe is empty. If not empty, convert StdTime from Unix timestamp (milliseconds) to datetime and print dataframe\nif df.empty:\n  print(f\"No {variable_name} data found between {start_date_time_str} - {end_date_time_str} for point ({coor_pts}).\")\nelse:\n  df['StdTime'] = pd.to_datetime(df['StdTime'], unit='ms')\n  print(df)\n\nNo NO2_Troposphere data found between 2025-10-06 00:00:00 - 2025-10-07 13:00:00 for point (-104.676, 39.856).\n\n\n\n\n4.3 Display the data in a chart\nThe data in the dataframe can be displayed in a chart. The chart can be exported for later use (this option is commented out by default).\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(df['StdTime'], df[variable_name], marker='o', linestyle='-')\n\n#Set title and labels--user may change\nplt.title(f'{variable_name} Over Time') #User may change title as desired\nplt.xlabel('Time (UTC)')\nplt.ylabel(f'{variable_name} (molecules/cm^2)') #Change unit as needed for variable selected (e.g., Ozone total is Dobson units)\n\n#Set grid, tick marks, and format\nplt.grid(True)\nax = plt.gca()\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Optional: Save the plot to a a local folder (include file path). Format set to PNG as default but can be changed.\n#plt.savefig(\"outputGraph.png\", format=\"png\")\n\n# Show plot in notebook\nplt.show()\n\n\n\n\n5. Create an interactive mapper\nThis mapper includes all of the TEMPO scans within the selected time period. The viewer shows the entire scans (not just around the point of interest). The scans can be stepped through using the time slider. Users may zoom in/out on the map. Users can hover over the map to see coordinates. Users can click on the map to have the coordinate point display below the mapper.\n\n#A handler that will update the map everytime the user moves the slider\ndef update_image(change):\n  tempo_image_service.time = [change.new,timestamps[4]]\n\n#Function to define interactive map behavior\ndef on_click(**kwargs):\n    \"\"\"When a user clicks on the map, print coordinates below map\"\"\"\n    if kwargs.get('type') == 'click':\n        print(str(kwargs.get('coordinates')))\n    \"\"\"When a user hovers mouse over map, display coordinates within map\"\"\"\n    if kwargs.get('type') == 'mousemove':\n        latlng = kwargs.get('coordinates')\n        lat, lng = latlng\n        coordinates_label.value = f\"Coordinates: ({lat:.5f}, {lng:.5f})\"\n\n\n# Initialize the map\nm = Map(center=(47,-122), zoom=3, basemap=basemaps.Esri.WorldTopoMap)\n\n#Set parameters for calling TEMPO image service\n'''Note: The rendering_rule rasterFunction holds the colormap associated with the image service.\nReplace with the appropriate colormap for best visualization depending on selected variable.\nNO2: rendering_rule={\"rasterFunction\":\"matter_RGB\"},\nHCHO: rendering_rule={\"rasterFunction\":\"haline_RGB\"},\nOzone Tot: rendering_rule={\"rasterFunction\":\"batlow_RGB\"}, '''\ntempo_image_service = ImageService(url=image_service_url,\n                                   rendering_rule={\"rasterFunction\":\"matter_RGB\"},\n                                   time=timestamps,\n                                   format=\"jpgpng\",\n                                   opacity=0.5,\n                                   )\n\n# Create a list with the user selected UTC times with time_values for easy visualization of time\ntime_strings = [convert_from_milliseconds(t) for t in timestamps]\n\n# Create a list of tuples to input in SelectionSlider's options for easy visualization of time\ntime_options = [(time_strings[i], timestamps[i]) for i in range(len(timestamps))]\n\n# Create the slider\nslider = SelectionSlider(description='Time:', options=time_options, layout=Layout(width='700px', height='20px'))\n#slider = SelectionSlider(description='Time:', options=timestamps, layout=Layout(width='700px', height='20px'))\n\n# Create a Label for the VBox\ntime_label = Label(value='Time Slider')\n\n#Listens to the slider's user input and helps update the map\nslider.observe(update_image, 'value')\n\n# create a VBox to contain the slider and be placed in the map\nvbox = VBox([slider, time_label])\n\n# Slider placed in bottomleft of the map\ncontrol = WidgetControl(widget=vbox, position='bottomleft')\n\n# Output widget to listen to the user's mouse hovering over the map\noutput = Output()\ncontroloutput = WidgetControl(widget=output, position='topright')\n\n# Label widget to display coordinates\ncoordinates_label = HTML(value=\"Coordinates: \")\ncoordinates_control = WidgetControl(widget=coordinates_label, position='bottomright')\n\n# Add all widgets to the map\nm.add(tempo_image_service)\nm.add(control)\nm.add(controloutput)\nm.add(coordinates_control)\n\n# When user hovers over the map coordinates_label gets updated and prints the coordinates where clicked\nm.on_interaction(on_click)\n\n# Call map\nm"
  }
]